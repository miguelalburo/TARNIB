{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "id": "rBvfs9rGz_-H"
   },
   "outputs": [],
   "source": [
    "# --- Notebook: LSTM for longitudinal admissions (Module 3) ---\n",
    "# Train: predict hospital_expire_flag per admission sequence (many-to-many)\n",
    "# Notes:\n",
    "# - Uses subject-level split (already done)\n",
    "# - Orders by admission_no (per patient)\n",
    "# - Drops leakage: deathtime, days_until_death (+ dod if exists)\n",
    "# - Excludes race_* from model input (kept for subgroup evaluation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2ok5UF4q0BkA",
    "outputId": "90fa0105-0f5c-42af-ee8a-bafaf47a4457"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 1 — Imports + Reproducibility\n",
    "# Core python and data handling libraries for randomness control, numerical computation and tabular data\n",
    "import os, random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# PyTorch core modules for building neural netowrks (nn), handling datasets and managing the variables sequences length\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "# Use Scikit-learn utilities for feature scaling and model performance evaluation\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score, precision_recall_fscore_support\n",
    "\n",
    "# Set a fixed random seed across the libraries to ensure reproducibilty of results\n",
    "SEED = 67\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# Select the computation device (GPU if available, otherwise CPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6blGOANA0tKH",
    "outputId": "32df2621-b4df-4ca2-eeca-40355ea228d1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((9388, 513), (2430, 513))"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 2 — Load CSVs\n",
    "# Define the file paths for the training and testing datasets\n",
    "train_path = \"/jupyter/work/module3/group_project/TARNIB/data/train_wide.csv\"\n",
    "test_path  = \"/jupyter/work/module3/group_project/TARNIB/data/test_wide.csv\"\n",
    "\n",
    "# Load the csv files into panda dataframes\n",
    "train = pd.read_csv(train_path)\n",
    "test = pd.read_csv(test_path)\n",
    "\n",
    "# Display the datasets dimensions (for sanity check)\n",
    "train.shape, test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1_Mmuw_H0-H2",
    "outputId": "a3fa11a2-4f45-4236-c1f3-2e25136ba486"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 3 — Mandatory split sanity check (no subject overlap)\n",
    "# Check that no patient subject_id appears in both the training and testing datasets\n",
    "overlap = len(set(train[\"subject_id\"]) & set(test[\"subject_id\"]))\n",
    "overlap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OYHYJeUY1Bk8",
    "outputId": "a41e338d-77bc-45c5-992f-998176b8923b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped leakage: ['days_until_death']\n"
     ]
    }
   ],
   "source": [
    "# Cell 4 — Drop leakage columns (MUST)\n",
    "# Identify the future related columns that would cause data leakage if used as predictors\n",
    "LEAK = [c for c in [\"deathtime\", \"dod\", \"days_until_death\", \"discharge_location_CHRONIC/LONG TERM ACUTE CARE\",\n",
    "                    \"discharge_location_DIED\", \"discharge_location_HOME\", \"discharge_location_HOME HEALTH CARE\",\n",
    "                    \"discharge_location_Other_discharge_location\", \"discharge_location_REHAB\",\n",
    "                    \"discharge_location_SKILLED NURSING FACILITY\", \"discharge_location_Unknown_discharge_location\"]\n",
    "        if c in train.columns]\n",
    "\n",
    "# Remove the leakage columns from both training and testing datasets\n",
    "train = train.drop(columns=LEAK)\n",
    "test  = test.drop(columns=LEAK)\n",
    "print(\"Dropped leakage:\", LEAK)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rMSqnoWD1SqM",
    "outputId": "d5ff86c7-4579-4665-ed06-fbdc228443a4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10,\n",
       " ['race_ASIAN',\n",
       "  'race_ASIAN - CHINESE',\n",
       "  'race_BLACK/AFRICAN AMERICAN',\n",
       "  'race_BLACK/CAPE VERDEAN',\n",
       "  'race_HISPANIC OR LATINO'])"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 5 — Basic column roles\n",
    "# Define the identifiers, ordering and target columns used throughout the pipeline\n",
    "ID_COLS    = [\"subject_id\", \"hadm_id\"]\n",
    "ORDER_COL  = \"admission_no\"          # sorting only\n",
    "Y_COL      = \"hospital_expire_flag\"  # target\n",
    "\n",
    "# Identify Race indicator columns for subgroup evaluation only (not used as predictors)\n",
    "race_cols = [c for c in train.columns if c.startswith(\"race_\")]\n",
    "len(race_cols), race_cols[:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 240
    },
    "id": "PFgrDOJz1XlM",
    "outputId": "56fbd902-0bcf-4c51-bde4-9df234ba63ca"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    1\n",
       "2    1\n",
       "3    1\n",
       "4    1\n",
       "Name: gender, dtype: int64"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 6 — Encode gender if needed (M/F -> 1/0)\n",
    "# define a function to convert categorical gender variable into a numeric format if applicable\n",
    "def encode_gender(df):\n",
    "    if \"gender\" in df.columns and df[\"gender\"].dtype == object:\n",
    "        df[\"gender\"] = df[\"gender\"].map({\"M\": 1, \"F\": 0}).astype(\"float32\")\n",
    "    return df\n",
    "\n",
    "# Apply gender encoding to both the training and testing datasets\n",
    "train = encode_gender(train)\n",
    "test  = encode_gender(test)\n",
    "\n",
    "# Inspect the encoded gender values to ensure successful transofmration\n",
    "train[\"gender\"].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hRVQ2jun1bVF",
    "outputId": "a66c4296-c352-4056-d233-1c761dacc608"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(497,\n",
       " [\"'NEO013'\",\n",
       "  \"'NEO070'\",\n",
       "  \"'CIR033'\",\n",
       "  \"'DIG024'\",\n",
       "  \"'EXT025'\",\n",
       "  \"'EXT027'\",\n",
       "  \"'GEN007'\",\n",
       "  \"'END001'\",\n",
       "  \"'DIG004'\",\n",
       "  \"'FAC025'\",\n",
       "  \"'FAC027'\",\n",
       "  \"'CIR009'\",\n",
       "  \"'BLD004'\",\n",
       "  \"'RSP011'\",\n",
       "  \"'CIR011'\"])"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 7 — Define feature columns (exclude IDs, order, label, race_*)\n",
    "# Specify the columns to exclude model inputs\n",
    "drop_from_X = set(ID_COLS + [ORDER_COL, Y_COL]) | set(race_cols) | {\"LoS\"}\n",
    "feature_cols = [c for c in train.columns if c not in drop_from_X]\n",
    "\n",
    "# Check the number of selected features and preview a subset of them\n",
    "len(feature_cols), feature_cols[:15]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 178
    },
    "id": "g3zOTAjg1vOF",
    "outputId": "a33c571b-ede7-4c3f-ebfa-11683b4a07be"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>'NEO013'</th>\n",
       "      <th>'NEO070'</th>\n",
       "      <th>'CIR033'</th>\n",
       "      <th>'DIG024'</th>\n",
       "      <th>'EXT025'</th>\n",
       "      <th>'EXT027'</th>\n",
       "      <th>'GEN007'</th>\n",
       "      <th>'END001'</th>\n",
       "      <th>'DIG004'</th>\n",
       "      <th>'FAC025'</th>\n",
       "      <th>...</th>\n",
       "      <th>language_Chinese</th>\n",
       "      <th>language_English</th>\n",
       "      <th>language_Russian</th>\n",
       "      <th>language_Spanish</th>\n",
       "      <th>language_Unknown/Other</th>\n",
       "      <th>marital_status_DIVORCED</th>\n",
       "      <th>marital_status_MARRIED</th>\n",
       "      <th>marital_status_SINGLE</th>\n",
       "      <th>marital_status_Unknown/Other</th>\n",
       "      <th>marital_status_WIDOWED</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 497 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      'NEO013'  'NEO070'  'CIR033'  'DIG024'  'EXT025'  'EXT027'  'GEN007'  \\\n",
       "mean      -0.0      -0.0      -0.0      -0.0       0.0      -0.0      -0.0   \n",
       "std        1.0       1.0       1.0       1.0       1.0       1.0       1.0   \n",
       "\n",
       "      'END001'  'DIG004'  'FAC025'  ...  language_Chinese  language_English  \\\n",
       "mean      -0.0       0.0      -0.0  ...               0.0              -0.0   \n",
       "std        1.0       1.0       1.0  ...               1.0               1.0   \n",
       "\n",
       "      language_Russian  language_Spanish  language_Unknown/Other  \\\n",
       "mean              -0.0              -0.0                     0.0   \n",
       "std                1.0               1.0                     1.0   \n",
       "\n",
       "      marital_status_DIVORCED  marital_status_MARRIED  marital_status_SINGLE  \\\n",
       "mean                      0.0                    -0.0                   -0.0   \n",
       "std                       1.0                     1.0                    1.0   \n",
       "\n",
       "      marital_status_Unknown/Other  marital_status_WIDOWED  \n",
       "mean                          -0.0                     0.0  \n",
       "std                            1.0                     1.0  \n",
       "\n",
       "[2 rows x 497 columns]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 8 — Impute missing values (train medians) + scale (fit on train only)\n",
    "# Handle missing values using the training set median\n",
    "train_medians = train[feature_cols].median(numeric_only=True)\n",
    "train[feature_cols] = train[feature_cols].fillna(train_medians)\n",
    "test[feature_cols]  = test[feature_cols].fillna(train_medians)\n",
    "\n",
    "# Fit feature scaler on training data only and apply to both datasets to avoid leakage\n",
    "scaler = StandardScaler()\n",
    "train[feature_cols] = scaler.fit_transform(train[feature_cols])\n",
    "test[feature_cols]  = scaler.transform(test[feature_cols])\n",
    "\n",
    "# Verifying the scaling (sanity check) by checking the features means and sd\n",
    "train[feature_cols].describe().loc[[\"mean\",\"std\"]].round(3).head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yhp5r58f130z",
    "outputId": "3fa328cc-484c-4091-9a73-29ab34c1030a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4000, 1000, 1, 101)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 9 — Sequence builder helpers\n",
    "# A function to derive a single race label per subject (for subgroup evaluation) and to convert tabular rows into per-subjects sequences\n",
    "def infer_race_label(row, race_cols):\n",
    "    if not race_cols:\n",
    "        return \"NO_RACE_COLS\"\n",
    "    vals = row[race_cols].to_numpy()\n",
    "    if np.all(np.isnan(vals)) or np.all(vals == 0):\n",
    "        return \"race_UNKNOWN\"\n",
    "    return race_cols[int(np.argmax(vals))]\n",
    "\n",
    "# A function to build variable length per subject_id: X is (T,F), y is (T,), and lengths store T for packing/padding later\n",
    "def build_sequences(df: pd.DataFrame):\n",
    "    # sort within patient\n",
    "    df = df.sort_values([\"subject_id\", ORDER_COL])\n",
    "\n",
    "    X_list, y_list, lengths, race_list = [], [], [], []\n",
    "\n",
    "    # Build subject_id level admission sequences (features, labels, lengths, race)\n",
    "    for sid, g in df.groupby(\"subject_id\", sort=False):\n",
    "        X = torch.tensor(g[feature_cols].to_numpy(np.float32))           # (T, F)\n",
    "        y = torch.tensor(g[Y_COL].to_numpy(np.float32))                  # (T,)\n",
    "        X_list.append(X)\n",
    "        y_list.append(y)\n",
    "        lengths.append(len(g))\n",
    "\n",
    "        if race_cols:\n",
    "            race_list.append(infer_race_label(g.iloc[0], race_cols))\n",
    "        else:\n",
    "            race_list.append(\"NO_RACE_COLS\")\n",
    "\n",
    "    lengths = torch.tensor(lengths, dtype=torch.long)\n",
    "    return X_list, y_list, lengths, race_list\n",
    "\n",
    "# Build train/test sequence lists (one sequence per subject) + lenght for later packing\n",
    "Xtr_list, ytr_list, Ltr, race_tr = build_sequences(train)\n",
    "Xte_list, yte_list, Lte, race_te = build_sequences(test)\n",
    "\n",
    "# Display number of subjects (sanity check) and number of admissions per subject\n",
    "len(Xtr_list), len(Xte_list), Ltr.min().item(), Ltr.max().item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "id": "7AXa5sor2AgW"
   },
   "outputs": [],
   "source": [
    "# Cell 10 — Dataset + collate (pads sequences)\n",
    "# A custom dataset class to store per-subject sequences, labels, sequence lengths and race metadata\n",
    "class SeqDataset(Dataset):\n",
    "    def __init__(self, X_list, y_list, lengths, race_list):\n",
    "        self.X = X_list\n",
    "        self.y = y_list\n",
    "        self.lengths = lengths\n",
    "        self.race = race_list\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx], self.lengths[idx], self.race[idx]\n",
    "\n",
    "# A custom collate function to pad variable length sequences within each batch\n",
    "def collate_fn(batch):\n",
    "    Xs, ys, lens, races = zip(*batch)\n",
    "    X_pad = pad_sequence(Xs, batch_first=True)                 # (B, T, F)\n",
    "    y_pad = pad_sequence(ys, batch_first=True, padding_value=-1.0)  # (B, T)\n",
    "    lens  = torch.tensor(lens, dtype=torch.long)\n",
    "    return X_pad, y_pad, lens, list(races)\n",
    "\n",
    "# To instantiate dataset objects for training and testing data\n",
    "train_ds = SeqDataset(Xtr_list, ytr_list, Ltr.tolist(), race_tr)\n",
    "test_ds  = SeqDataset(Xte_list, yte_list, Lte.tolist(), race_te)\n",
    "\n",
    "# Create dataloaders to generate padded mimi batches during training and evaluation\n",
    "BATCH_SIZE = 64\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True,  collate_fn=collate_fn)\n",
    "test_loader  = DataLoader(test_ds,  batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WXsN_eqG2GCO",
    "outputId": "8e003d4a-4548-44f9-a79d-a5db89cf7001"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTMSeq(\n",
       "  (lstm): LSTM(497, 64, batch_first=True)\n",
       "  (fc): Linear(in_features=64, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 11 — LSTM model (many-to-many logits: one per timestep)\n",
    "# Define an LSTM-based sequence model that outputs a prediction at each timestep\n",
    "class LSTMSeq(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim=64, num_layers=1, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_dim,\n",
    "            hidden_size=hidden_dim,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            dropout=dropout if num_layers > 1 else 0.0\n",
    "        )\n",
    "        self.fc = nn.Linear(hidden_dim, 1)\n",
    "\n",
    "# Define a Forward pass that handle padded sequences and produce per timestep logits\n",
    "    def forward(self, x, lengths):\n",
    "        packed = pack_padded_sequence(x, lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
    "        packed_out, _ = self.lstm(packed)\n",
    "        out, _ = pad_packed_sequence(packed_out, batch_first=True)  # (B, T, H)\n",
    "        logits = self.fc(out).squeeze(-1)                           # (B, T)\n",
    "        return logits\n",
    "\n",
    "# Instantiate the LSTM model and move it to the selected device\n",
    "model = LSTMSeq(input_dim=len(feature_cols), hidden_dim=64, num_layers=1, dropout=0.0).to(device)\n",
    "model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QOiNGMki2KDE",
    "outputId": "b5042edc-9b49-4d74-a277-828e1331d3f1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(219, 9169, 41.86758041381836)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 12 — Loss with class imbalance (pos_weight) + masked timesteps\n",
    "# Compute class imbalance from training labels to weight the positive class during loss calculation\n",
    "y_flat = np.concatenate([y.numpy() for y in ytr_list])\n",
    "pos = (y_flat == 1).sum()\n",
    "neg = (y_flat == 0).sum()\n",
    "\n",
    "# Define positive class weight (neg/pos) for use in weighted binary cross-entropy\n",
    "pos_weight = torch.tensor([neg / max(pos, 1)], dtype=torch.float32).to(device)\n",
    "pos, neg, pos_weight.item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "id": "tVWZNX3T2PM1"
   },
   "outputs": [],
   "source": [
    "# Cell 13 — Train/eval utilities\n",
    "# Define weighted BCE loss (handles class imbalance) and Adam optimiser for training\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# Compute BCE loss while ignoring padded timesteps (label == -1)\n",
    "def masked_bce_loss(logits, y):\n",
    "    # y has padding -1\n",
    "    mask = (y != -1)\n",
    "    return criterion(logits[mask], y[mask])\n",
    "\n",
    "# Evaluate overall performance on a DataLoader (AUC, Precision, Recall, F1) using only real timesteps\n",
    "@torch.no_grad() # Disables gradient tracking, Makes evaluation faster & uses less memory\n",
    "def eval_loader(loader):\n",
    "    model.eval()\n",
    "    all_probs, all_true = [], []\n",
    "\n",
    "    for X_pad, y_pad, lengths, _races in loader:\n",
    "        X_pad = X_pad.to(device)\n",
    "        y_pad = y_pad.to(device)\n",
    "        logits = model(X_pad, lengths)\n",
    "        mask = (y_pad != -1)\n",
    "\n",
    "        probs = torch.sigmoid(logits[mask]).detach().cpu().numpy()\n",
    "        true  = y_pad[mask].detach().cpu().numpy()\n",
    "\n",
    "        all_probs.append(probs)\n",
    "        all_true.append(true)\n",
    "\n",
    "#\n",
    "    probs = np.concatenate(all_probs) if all_probs else np.array([])\n",
    "    true  = np.concatenate(all_true)  if all_true  else np.array([])\n",
    "\n",
    "    auc = roc_auc_score(true, probs) if len(np.unique(true)) > 1 else np.nan\n",
    "    pred = (probs >= 0.5).astype(int)\n",
    "\n",
    "    p, r, f1, _ = precision_recall_fscore_support(true, pred, average=\"binary\", zero_division=0)\n",
    "    return {\"AUC\": auc, \"Precision\": p, \"Recall\": r, \"F1\": f1}\n",
    "\n",
    "# Evaluate performance by race group (Objective 3) by aggregating admission level predictions per patient race label\n",
    "@torch.no_grad()\n",
    "def eval_by_race(loader):\n",
    "    # aggregates admission-level predictions by patient race label\n",
    "    model.eval()\n",
    "    buckets = {}  # race -> list of (true, prob)\n",
    "\n",
    "    for X_pad, y_pad, lengths, races in loader:\n",
    "        X_pad = X_pad.to(device)\n",
    "        y_pad = y_pad.to(device)\n",
    "        logits = model(X_pad, lengths)\n",
    "        probs_full = torch.sigmoid(logits).detach().cpu().numpy()\n",
    "        y_full     = y_pad.detach().cpu().numpy()\n",
    "\n",
    "        for i, race in enumerate(races):\n",
    "            T = lengths[i].item()\n",
    "            true = y_full[i, :T]\n",
    "            prob = probs_full[i, :T]\n",
    "            good = (true != -1)\n",
    "            true = true[good]\n",
    "            prob = prob[good]\n",
    "            if len(true) == 0:\n",
    "                continue\n",
    "            buckets.setdefault(race, []).append((true, prob))\n",
    "\n",
    "# Compute metrics per race group by concatenating patient level predictions\n",
    "    rows = []\n",
    "    for race, lst in buckets.items():\n",
    "        true = np.concatenate([t for t, _ in lst])\n",
    "        prob = np.concatenate([p for _, p in lst])\n",
    "        if len(np.unique(true)) < 2:\n",
    "            auc = np.nan\n",
    "        else:\n",
    "            auc = roc_auc_score(true, prob)\n",
    "        pred = (prob >= 0.5).astype(int)\n",
    "        p, r, f1, _ = precision_recall_fscore_support(true, pred, average=\"binary\", zero_division=0)\n",
    "        rows.append((race, len(lst), auc, p, r, f1))\n",
    "\n",
    "# Return results as a table sorted by group size\n",
    "    out = pd.DataFrame(rows, columns=[\"race_group\", \"n_patients\", \"AUC\", \"Precision\", \"Recall\", \"F1\"])\n",
    "    return out.sort_values([\"n_patients\"], ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2hSPbHNy2Xg0",
    "outputId": "58c5d10c-dcd7-4259-96ca-b4514d4ae2de"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 | loss=1.2221 | AUC=0.922 P=0.074 R=0.945 F1=0.136\n",
      "Epoch 02 | loss=0.7571 | AUC=0.947 P=0.154 R=0.909 F1=0.264\n",
      "Epoch 03 | loss=0.4198 | AUC=0.945 P=0.201 R=0.764 F1=0.318\n",
      "Epoch 04 | loss=0.2459 | AUC=0.927 P=0.287 R=0.673 F1=0.402\n",
      "Epoch 05 | loss=0.1611 | AUC=0.917 P=0.330 R=0.582 F1=0.421\n",
      "Epoch 06 | loss=0.1098 | AUC=0.914 P=0.372 R=0.582 F1=0.454\n",
      "Epoch 07 | loss=0.0799 | AUC=0.909 P=0.397 R=0.564 F1=0.466\n",
      "Early stopping.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9473531100478468"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 14 — Training loop (with simple early stopping on AUC)\n",
    "# Set training hyperparameters and early stopping criteria\n",
    "EPOCHS = 25\n",
    "best_auc = -np.inf\n",
    "patience = 5\n",
    "bad = 0\n",
    "\n",
    "# Main training loop over epochs\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    model.train()\n",
    "    running = 0.0\n",
    "\n",
    "    for X_pad, y_pad, lengths, _races in train_loader:\n",
    "        X_pad = X_pad.to(device)\n",
    "        y_pad = y_pad.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(X_pad, lengths)\n",
    "        loss = masked_bce_loss(logits, y_pad)\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "\n",
    "        running += loss.item()\n",
    "\n",
    "# Evaluate model on test set and report metrics\n",
    "    metrics = eval_loader(test_loader)\n",
    "    avg_loss = running / max(len(train_loader), 1)\n",
    "\n",
    "    print(f\"Epoch {epoch:02d} | loss={avg_loss:.4f} | \"\n",
    "          f\"AUC={metrics['AUC']:.3f} P={metrics['Precision']:.3f} \"\n",
    "          f\"R={metrics['Recall']:.3f} F1={metrics['F1']:.3f}\")\n",
    "\n",
    "    # Save best model and stop training if AUC does not improve\n",
    "    if metrics[\"AUC\"] > best_auc + 1e-4:\n",
    "        best_auc = metrics[\"AUC\"]\n",
    "        bad = 0\n",
    "        torch.save(model.state_dict(), \"best_lstm_mortality.pt\")\n",
    "    else:\n",
    "        bad += 1\n",
    "        if bad >= patience:\n",
    "            print(\"Early stopping.\")\n",
    "            break\n",
    "\n",
    "best_auc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7A1aBDAj2gi_",
    "outputId": "91191db5-246a-4c91-84ed-49bf38217b9f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_74/3805121918.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(\"best_lstm_mortality.pt\", map_location=device))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'AUC': 0.9473531100478468,\n",
       " 'Precision': 0.15432098765432098,\n",
       " 'Recall': 0.9090909090909091,\n",
       " 'F1': 0.2638522427440633}"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 15 — Load best model + final evaluation\n",
    "# Load the best performing model checkpoint and evaluate it on the test dataset\n",
    "model.load_state_dict(torch.load(\"best_lstm_mortality.pt\", map_location=device))\n",
    "final_metrics = eval_loader(test_loader)\n",
    "final_metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wyilE9ch2qHN",
    "outputId": "42f45b6f-865c-419e-e264-e4f14540db3f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: best_lstm_mortality.pt, scaler.joblib, feature_cols.joblib\n"
     ]
    }
   ],
   "source": [
    "# Cell 16 — Save scaler + feature columns (for reproducibility)\n",
    "# joblib library to efficiently save and load Python objects\n",
    "import joblib\n",
    "\n",
    "# Save the fitted scaler and feature column order to disk\n",
    "joblib.dump(scaler, \"scaler.joblib\")\n",
    "joblib.dump(feature_cols, \"feature_cols.joblib\")\n",
    "\n",
    "print(\"Saved: best_lstm_mortality.pt, scaler.joblib, feature_cols.joblib\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 335
    },
    "id": "6T03jY222zF8",
    "outputId": "eed2c707-cf52-4655-f8c8-282a42608980"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    4000.000000\n",
       "mean        2.347000\n",
       "std         3.484268\n",
       "min         1.000000\n",
       "25%         1.000000\n",
       "50%         1.000000\n",
       "75%         2.000000\n",
       "max       101.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 17 — Quick note about sequence lengths\n",
    "# Computes summary statistics of sequence lengths to describe variability in time series duration\n",
    "seq_stats = pd.Series(Ltr.tolist()).describe()\n",
    "seq_stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4fIhRXA_BMR_",
    "outputId": "ce789152-ca71-47e2-9988-ba49dd47c11b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2430, array([1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]))"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 18 - extract model predictions on the test set\n",
    "# Generate probability predictions, binary predictions and true labels from the test set\n",
    "@torch.no_grad()\n",
    "def get_test_predictions(loader, threshold=0.5):\n",
    "    model.eval()\n",
    "    all_probs, all_preds, all_true = [], [], []\n",
    "\n",
    "# Iterate through the test DataLoader and collect masked predictions\n",
    "    for X_pad, y_pad, lengths, _ in loader:\n",
    "        X_pad = X_pad.to(device)\n",
    "        y_pad = y_pad.to(device)\n",
    "\n",
    "        logits = model(X_pad, lengths)\n",
    "        probs = torch.sigmoid(logits)\n",
    "\n",
    "        mask = (y_pad != -1)\n",
    "\n",
    "        probs = probs[mask].cpu().numpy()\n",
    "        true  = y_pad[mask].cpu().numpy()\n",
    "        preds = (probs >= threshold).astype(int)\n",
    "\n",
    "        all_probs.append(probs)\n",
    "        all_preds.append(preds)\n",
    "        all_true.append(true)\n",
    "\n",
    "    return (\n",
    "        np.concatenate(all_probs),\n",
    "        np.concatenate(all_preds),\n",
    "        np.concatenate(all_true)\n",
    "    )\n",
    "\n",
    "# Run prediction function on the test set and inspect output size and first predictions\n",
    "test_probs, test_preds, test_true = get_test_predictions(test_loader)\n",
    "\n",
    "len(test_preds), test_preds[:20]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XcYRressBNzr",
    "outputId": "5f363a38-089b-4e66-931d-09e0874a4460"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2101,  274],\n",
       "       [   5,   50]])"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 19 - summarize classification performance on the test set\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Generate confusion matrix from true and predicted test labels\n",
    "cm = confusion_matrix(test_true, test_preds)\n",
    "cm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 407
    },
    "id": "dQa16fAoBQ5l",
    "outputId": "10998f72-9b42-448d-b4ac-dfcde8ba7893"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cell 20 - Visualize the confusion matrix as a heatmap\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Plot the confusion matrix with annotations and labeled axes\n",
    "plt.figure(figsize=(5,4))\n",
    "sns.heatmap(\n",
    "    cm,\n",
    "    annot=True,\n",
    "    fmt=\"d\",\n",
    "    cmap=\"Blues\",\n",
    "    xticklabels=[\"Predicted 0\", \"Predicted 1\"],\n",
    "    yticklabels=[\"Actual 0\", \"Actual 1\"]\n",
    ")\n",
    "plt.title(\"Confusion Matrix — LSTM Mortality Prediction\")\n",
    "plt.ylabel(\"True label\")\n",
    "plt.xlabel(\"Predicted label\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "id": "0emnWnj2nvMF"
   },
   "outputs": [],
   "source": [
    "# Cell 20.5A — Define permutation importance for LSTM (classification)\n",
    "# Define a function that shuffles one feature at a time and measures the resulting AUC drop\n",
    "@torch.no_grad()\n",
    "def permutation_importance_lstm(\n",
    "    model, loader, feature_cols, baseline_auc, n_repeats=1\n",
    "):\n",
    "    model.eval()\n",
    "    importances = []\n",
    "\n",
    "# Loop over each feature and measure AUC drop when that feature is shuffled\n",
    "    for j, feat in enumerate(feature_cols):\n",
    "        drops = []\n",
    "\n",
    "        for _ in range(n_repeats):\n",
    "            all_probs, all_true = [], []\n",
    "\n",
    "            for X_pad, y_pad, lengths, _ in loader:\n",
    "                X_pad = X_pad.clone()\n",
    "                y_pad = y_pad.to(device)\n",
    "\n",
    "                # shuffle feature j\n",
    "                vals = X_pad[:, :, j].cpu().numpy().flatten()\n",
    "                np.random.shuffle(vals)\n",
    "                X_pad[:, :, j] = torch.tensor(\n",
    "                    vals.reshape(X_pad[:, :, j].shape),\n",
    "                    dtype=X_pad.dtype\n",
    "                )\n",
    "\n",
    "                X_pad = X_pad.to(device)\n",
    "                logits = model(X_pad, lengths)\n",
    "                mask = (y_pad != -1)\n",
    "\n",
    "                probs = torch.sigmoid(logits[mask]).cpu().numpy()\n",
    "                true  = y_pad[mask].cpu().numpy()\n",
    "\n",
    "                all_probs.append(probs)\n",
    "                all_true.append(true)\n",
    "\n",
    "            probs = np.concatenate(all_probs)\n",
    "            true  = np.concatenate(all_true)\n",
    "\n",
    "            auc = roc_auc_score(true, probs) if len(np.unique(true)) > 1 else np.nan\n",
    "            drops.append(baseline_auc - auc)\n",
    "\n",
    "        importances.append(np.nanmean(drops))\n",
    "\n",
    "# Return ranked feature importances as mean AUC drop after shuffling each feature\n",
    "    return pd.DataFrame({\n",
    "        \"feature\": feature_cols,\n",
    "        \"importance_auc_drop\": importances\n",
    "    }).sort_values(\"importance_auc_drop\", ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 519
    },
    "id": "XVvKefebml8j",
    "outputId": "fd1bf292-3f95-4610-8c56-54db703023a1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance_auc_drop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>'FAC010'</td>\n",
       "      <td>0.015058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>'NVS020'</td>\n",
       "      <td>0.011376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>'RSP012'</td>\n",
       "      <td>0.010963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>'CIR021'</td>\n",
       "      <td>0.007740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>'SKN003'</td>\n",
       "      <td>0.004754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>'CIR015'</td>\n",
       "      <td>0.004731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>'NEO060'</td>\n",
       "      <td>0.004379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>'INJ035'</td>\n",
       "      <td>0.004211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>'CIR025'</td>\n",
       "      <td>0.003989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>'INF006'</td>\n",
       "      <td>0.002718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>admission_type_EW EMER.</td>\n",
       "      <td>0.002603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>'SYM003'</td>\n",
       "      <td>0.002335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>'MUS023'</td>\n",
       "      <td>0.002243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>'GEN002'</td>\n",
       "      <td>0.002228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>'FAC025'</td>\n",
       "      <td>0.002059</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     feature  importance_auc_drop\n",
       "98                  'FAC010'             0.015058\n",
       "94                  'NVS020'             0.011376\n",
       "75                  'RSP012'             0.010963\n",
       "222                 'CIR021'             0.007740\n",
       "203                 'SKN003'             0.004754\n",
       "210                 'CIR015'             0.004731\n",
       "364                 'NEO060'             0.004379\n",
       "67                  'INJ035'             0.004211\n",
       "76                  'CIR025'             0.003989\n",
       "77                  'INF006'             0.002718\n",
       "471  admission_type_EW EMER.             0.002603\n",
       "153                 'SYM003'             0.002335\n",
       "319                 'MUS023'             0.002243\n",
       "49                  'GEN002'             0.002228\n",
       "9                   'FAC025'             0.002059"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 20.5B — Feature importance for mortality (Permutation Importance)\n",
    "# Compute baseline AUC and estimate feature importance using permutation based AUC drop\n",
    "baseline_auc = eval_loader(test_loader)[\"AUC\"]\n",
    "\n",
    "# Apply permutation importance to rank features by their impact on mortality prediction\n",
    "feature_importance_mortality = permutation_importance_lstm(\n",
    "    model=model,\n",
    "    loader=test_loader,\n",
    "    feature_cols=feature_cols,   # mortality feature set (LoS excluded)\n",
    "    baseline_auc=baseline_auc,\n",
    "    n_repeats=1\n",
    ")\n",
    "\n",
    "feature_importance_mortality.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sHcQeDuRC-OH",
    "outputId": "0169431b-9bf4-4c31-c0ad-af4a9eba159a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "497"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 21 — Define LoS regression target\n",
    "LOS_COL = \"LoS\"\n",
    "\n",
    "# Feature columns for LoS prediction (remove LoS itself)\n",
    "los_feature_cols = [c for c in feature_cols if c != LOS_COL]\n",
    "\n",
    "len(los_feature_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "id": "ipqqPGTxDEs_"
   },
   "outputs": [],
   "source": [
    "# Cell 22 — Build LoS sequences (many-to-many regression)\n",
    "# Construct per subject variable length input and target sequences for LoS regression\n",
    "def build_los_sequences(df: pd.DataFrame):\n",
    "    df = df.sort_values([\"subject_id\", ORDER_COL])\n",
    "\n",
    "    X_list, y_list, lengths = [], [], []\n",
    "\n",
    "    for _, g in df.groupby(\"subject_id\", sort=False):\n",
    "        X = torch.tensor(g[los_feature_cols].to_numpy(np.float32))   # (T, F)\n",
    "        y = torch.tensor(g[LOS_COL].to_numpy(np.float32))            # (T,)\n",
    "        X_list.append(X)\n",
    "        y_list.append(y)\n",
    "        lengths.append(len(g))\n",
    "\n",
    "    return X_list, y_list, torch.tensor(lengths, dtype=torch.long)\n",
    "\n",
    "# Build LoS input target sequences for training and test datasets\n",
    "Xtr_los, ytr_los, Ltr_los = build_los_sequences(train)\n",
    "Xte_los, yte_los, Lte_los = build_los_sequences(test)\n",
    "\n",
    "# Build per subject LoS sequences while attaching a single race label per patient for fairness evaluation\n",
    "def build_los_sequences_with_race(df: pd.DataFrame):\n",
    "    df = df.sort_values([\"subject_id\", ORDER_COL])\n",
    "\n",
    "    X_list, y_list, lengths, race_list = [], [], [], []\n",
    "\n",
    "    for sid, g in df.groupby(\"subject_id\", sort=False):\n",
    "        X = torch.tensor(g[los_feature_cols].to_numpy(np.float32))   # (T, F)\n",
    "        y = torch.tensor(g[LOS_COL].to_numpy(np.float32))            # (T,)\n",
    "        X_list.append(X)\n",
    "        y_list.append(y)\n",
    "        lengths.append(len(g))\n",
    "\n",
    "        if race_cols:\n",
    "            race_list.append(infer_race_label(g.iloc[0], race_cols))   # same logic as mortality\n",
    "        else:\n",
    "            race_list.append(\"NO_RACE_COLS\")\n",
    "\n",
    "    lengths = torch.tensor(lengths, dtype=torch.long)\n",
    "    return X_list, y_list, lengths, race_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "id": "ffyMRjYxDI6-"
   },
   "outputs": [],
   "source": [
    "# Cell 23 — DataLoaders for LoS regression\n",
    "# Define dataset and collate function to handle variable-length LoS sequences\n",
    "class LoSDataset(Dataset):\n",
    "    def __init__(self, X_list, y_list, lengths):\n",
    "        self.X = X_list\n",
    "        self.y = y_list\n",
    "        self.lengths = lengths\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx], self.lengths[idx]\n",
    "\n",
    "# Pad variable length input and target sequences for batching\n",
    "def los_collate_fn(batch):\n",
    "    Xs, ys, lens = zip(*batch)\n",
    "    X_pad = pad_sequence(Xs, batch_first=True)\n",
    "    y_pad = pad_sequence(ys, batch_first=True, padding_value=-1.0)\n",
    "    lens  = torch.tensor(lens, dtype=torch.long)\n",
    "    return X_pad, y_pad, lens\n",
    "\n",
    "# Create DataLoaders for training and testing LoS regression models\n",
    "train_los_loader = DataLoader(\n",
    "    LoSDataset(Xtr_los, ytr_los, Ltr_los),\n",
    "    batch_size=64, shuffle=True, collate_fn=los_collate_fn\n",
    ")\n",
    "\n",
    "test_los_loader = DataLoader(\n",
    "    LoSDataset(Xte_los, yte_los, Lte_los),\n",
    "    batch_size=64, shuffle=False, collate_fn=los_collate_fn\n",
    ")\n",
    "\n",
    "# Dataset class for LoS regression that includes race metadata per subject\n",
    "class LoSDatasetRace(Dataset):\n",
    "    def __init__(self, X_list, y_list, lengths, race_list):\n",
    "        self.X = X_list\n",
    "        self.y = y_list\n",
    "        self.lengths = lengths\n",
    "        self.race = race_list\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx], self.lengths[idx], self.race[idx]\n",
    "\n",
    "# Collate function that pads LoS sequences and preserves race labels for subgroup evaluation\n",
    "def los_collate_fn_race(batch):\n",
    "    Xs, ys, lens, races = zip(*batch)\n",
    "    X_pad = pad_sequence(Xs, batch_first=True)\n",
    "    y_pad = pad_sequence(ys, batch_first=True, padding_value=-1.0)\n",
    "    lens  = torch.tensor(lens, dtype=torch.long)\n",
    "    return X_pad, y_pad, lens, list(races)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "id": "WDVZ_ubCDLwv"
   },
   "outputs": [],
   "source": [
    "# Cell 24 — LSTM regression model\n",
    "# Define an LSTM based many to many regression model for predicting LoS at each timestep\n",
    "class LSTM_LoS(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim=64):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, 1)\n",
    "\n",
    "# Forward pass using packed sequences to handle variable-length inputs\n",
    "    def forward(self, x, lengths):\n",
    "        packed = pack_padded_sequence(x, lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
    "        packed_out, _ = self.lstm(packed)\n",
    "        out, _ = pad_packed_sequence(packed_out, batch_first=True)\n",
    "        preds = self.fc(out).squeeze(-1)\n",
    "        return preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "id": "5ITEeAehDfQF"
   },
   "outputs": [],
   "source": [
    "# Cell 25 — Loss & metrics (MSE / RMSE / MAE / R²)\n",
    "# Initialize LoS regression model, loss function and evaluation metrics with masking\n",
    "los_model = LSTM_LoS(input_dim=len(los_feature_cols)).to(device)\n",
    "los_optimizer = torch.optim.Adam(los_model.parameters(), lr=1e-3)\n",
    "los_criterion = nn.MSELoss()\n",
    "\n",
    "# Define masked mean squared error to ignore padded timesteps\n",
    "def masked_mse(pred, true):\n",
    "    mask = (true != -1)\n",
    "    return los_criterion(pred[mask], true[mask])\n",
    "\n",
    "# Evaluate LoS model using MSE, RMSE, MAE, and R² on non-padded timesteps\n",
    "@torch.no_grad()\n",
    "def eval_los(loader):\n",
    "    los_model.eval()\n",
    "    all_preds, all_true = [], []\n",
    "\n",
    "    for X_pad, y_pad, lengths in loader:\n",
    "        X_pad = X_pad.to(device)\n",
    "        y_pad = y_pad.to(device)\n",
    "\n",
    "        preds = los_model(X_pad, lengths)\n",
    "        mask = (y_pad != -1)\n",
    "\n",
    "        all_preds.append(preds[mask].cpu().numpy())\n",
    "        all_true.append(y_pad[mask].cpu().numpy())\n",
    "\n",
    "# Aggregate predictions and compute regression metrics\n",
    "    y_pred = np.concatenate(all_preds)\n",
    "    y_true = np.concatenate(all_true)\n",
    "\n",
    "    mse  = np.mean((y_pred - y_true) ** 2)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae  = np.mean(np.abs(y_pred - y_true))\n",
    "    r2   = 1 - np.sum((y_true - y_pred) ** 2) / np.sum((y_true - np.mean(y_true)) ** 2)\n",
    "\n",
    "    return mse, rmse, mae, r2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dbNv3_EgDmNW",
    "outputId": "da435364-10a4-4976-8140-ca419a07a76a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 | TrainLoss=4883.135 | MSE=64.397 | RMSE=8.025 | MAE=3.979 | R2=-0.227\n",
      "Epoch 02 | TrainLoss=4003.570 | MSE=51.068 | RMSE=7.146 | MAE=3.468 | R2=0.027\n",
      "Epoch 03 | TrainLoss=3270.588 | MSE=44.211 | RMSE=6.649 | MAE=3.138 | R2=0.158\n",
      "Epoch 04 | TrainLoss=2789.398 | MSE=40.386 | RMSE=6.355 | MAE=3.021 | R2=0.230\n",
      "Epoch 05 | TrainLoss=2507.986 | MSE=38.330 | RMSE=6.191 | MAE=2.930 | R2=0.270\n",
      "Epoch 06 | TrainLoss=2272.586 | MSE=37.103 | RMSE=6.091 | MAE=2.920 | R2=0.293\n",
      "Epoch 07 | TrainLoss=2090.141 | MSE=36.405 | RMSE=6.034 | MAE=2.882 | R2=0.306\n",
      "Epoch 08 | TrainLoss=2093.899 | MSE=36.003 | RMSE=6.000 | MAE=2.869 | R2=0.314\n",
      "Epoch 09 | TrainLoss=1904.264 | MSE=35.652 | RMSE=5.971 | MAE=2.889 | R2=0.321\n",
      "Epoch 10 | TrainLoss=1674.387 | MSE=35.334 | RMSE=5.944 | MAE=2.885 | R2=0.327\n",
      "Epoch 11 | TrainLoss=1607.312 | MSE=35.027 | RMSE=5.918 | MAE=2.889 | R2=0.333\n",
      "Epoch 12 | TrainLoss=1455.029 | MSE=35.061 | RMSE=5.921 | MAE=2.863 | R2=0.332\n",
      "Epoch 13 | TrainLoss=1297.933 | MSE=34.695 | RMSE=5.890 | MAE=2.876 | R2=0.339\n",
      "Epoch 14 | TrainLoss=1201.736 | MSE=34.881 | RMSE=5.906 | MAE=2.904 | R2=0.335\n",
      "Epoch 15 | TrainLoss=1152.936 | MSE=34.522 | RMSE=5.876 | MAE=2.923 | R2=0.342\n",
      "Epoch 16 | TrainLoss=1113.824 | MSE=34.849 | RMSE=5.903 | MAE=2.928 | R2=0.336\n",
      "Epoch 17 | TrainLoss=1024.397 | MSE=34.798 | RMSE=5.899 | MAE=2.951 | R2=0.337\n",
      "Epoch 18 | TrainLoss=1002.684 | MSE=34.726 | RMSE=5.893 | MAE=2.962 | R2=0.338\n",
      "Epoch 19 | TrainLoss=800.586 | MSE=34.930 | RMSE=5.910 | MAE=3.002 | R2=0.334\n",
      "Epoch 20 | TrainLoss=909.588 | MSE=35.064 | RMSE=5.922 | MAE=2.988 | R2=0.332\n",
      "Early stopping.\n"
     ]
    }
   ],
   "source": [
    "# Cell 26 — Train LoS regression model\n",
    "# Train the LoS LSTM using masked MSE loss with early stopping based on test RMSE\n",
    "EPOCHS = 20\n",
    "best_rmse = np.inf\n",
    "patience = 5\n",
    "bad = 0\n",
    "\n",
    "# Training loop with validation based early stopping\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    los_model.train()\n",
    "    total_loss = 0.0\n",
    "\n",
    "    for X_pad, y_pad, lengths in train_los_loader:\n",
    "        X_pad = X_pad.to(device)\n",
    "        y_pad = y_pad.to(device)\n",
    "\n",
    "        los_optimizer.zero_grad()\n",
    "        preds = los_model(X_pad, lengths)\n",
    "        loss = masked_mse(preds, y_pad)\n",
    "        loss.backward()\n",
    "        los_optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "# Evaluate model performance on the test set after each epoch\n",
    "    mse, rmse, mae, r2 = eval_los(test_los_loader)\n",
    "\n",
    "    print(f\"Epoch {epoch:02d} | TrainLoss={total_loss:.3f} | MSE={mse:.3f} | RMSE={rmse:.3f} | MAE={mae:.3f} | R2={r2:.3f}\")\n",
    "\n",
    "    if rmse < best_rmse:\n",
    "        best_rmse = rmse\n",
    "        bad = 0\n",
    "        torch.save(los_model.state_dict(), \"best_lstm_los.pt\")\n",
    "    else:\n",
    "        bad += 1\n",
    "        if bad >= patience:\n",
    "            print(\"Early stopping.\")\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AEfyw82CDvgo",
    "outputId": "8626866e-b5da-444e-ba20-d0af2aae476a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_74/1113631208.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  los_model.load_state_dict(torch.load(\"best_lstm_los.pt\", map_location=device))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(34.52233, 5.875571, 2.9227092, 0.3422069549560547)"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 27 — Final LoS test performance\n",
    "# Load the best LoS model and report final regression metrics on the test set\n",
    "los_model.load_state_dict(torch.load(\"best_lstm_los.pt\", map_location=device))\n",
    "final_mse, final_rmse, final_mae, final_r2 = eval_los(test_los_loader)\n",
    "\n",
    "final_mse, final_rmse, final_mae, final_r2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 335
    },
    "id": "LBK9sYFeEMGh",
    "outputId": "34346072-ccb7-4599-aa57-3cdabb81dcb9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    9388.000000\n",
       "mean        4.919814\n",
       "std         7.635377\n",
       "min        -0.867361\n",
       "25%         1.135417\n",
       "50%         2.838194\n",
       "75%         5.724653\n",
       "max       207.152778\n",
       "Name: LoS, dtype: float64"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 27.5 - Describe the distribution of Length of Stay values\n",
    "train[\"LoS\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "id": "jp-nzxbzmxwP"
   },
   "outputs": [],
   "source": [
    "# Cell 28 — Feature importance for LoS (Permutation Importance)\n",
    "# Define permutation based feature importance for LoS regression using RMSE increase\n",
    "@torch.no_grad()\n",
    "def permutation_importance_lstm_regression(\n",
    "    model, loader, feature_cols, baseline_rmse\n",
    "):\n",
    "    model.eval()\n",
    "    importances = []\n",
    "\n",
    "# Define permutation-based feature importance for LoS regression using RMSE increase\n",
    "    for j, feat in enumerate(feature_cols):\n",
    "        all_preds, all_true = [], []\n",
    "\n",
    "        for X_pad, y_pad, lengths in loader:\n",
    "            X_pad = X_pad.clone()\n",
    "            y_pad = y_pad.to(device)\n",
    "\n",
    "            vals = X_pad[:, :, j].cpu().numpy().flatten()\n",
    "            np.random.shuffle(vals)\n",
    "            X_pad[:, :, j] = torch.tensor(\n",
    "                vals.reshape(X_pad[:, :, j].shape),\n",
    "                dtype=X_pad.dtype\n",
    "            )\n",
    "\n",
    "            X_pad = X_pad.to(device)\n",
    "            preds = model(X_pad, lengths)\n",
    "\n",
    "            mask = (y_pad != -1)\n",
    "            all_preds.append(preds[mask].cpu().numpy())\n",
    "            all_true.append(y_pad[mask].cpu().numpy())\n",
    "\n",
    "        y_pred = np.concatenate(all_preds)\n",
    "        y_true = np.concatenate(all_true)\n",
    "\n",
    "        rmse = np.sqrt(np.mean((y_pred - y_true) ** 2))\n",
    "        importances.append(rmse - baseline_rmse)\n",
    "\n",
    "# Return ranked feature importances as RMSE increase after shuffling each feature\n",
    "    return pd.DataFrame({\n",
    "        \"feature\": feature_cols,\n",
    "        \"importance_rmse_increase\": importances\n",
    "    }).sort_values(\"importance_rmse_increase\", ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 519
    },
    "id": "Mnx7bQdMm0w7",
    "outputId": "05215e91-412b-4449-896e-b88e818a873f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance_rmse_increase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>admission_type_EU OBSERVATION</td>\n",
       "      <td>0.061468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>'NEO060'</td>\n",
       "      <td>0.059976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>'END008'</td>\n",
       "      <td>0.050130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>'EXT025'</td>\n",
       "      <td>0.031591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>'RSP012'</td>\n",
       "      <td>0.030544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>'NVS020'</td>\n",
       "      <td>0.029725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>'INF002'</td>\n",
       "      <td>0.028008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>'BLD010'</td>\n",
       "      <td>0.026619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>admission_location_Unknown/Other</td>\n",
       "      <td>0.026128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>admission_type_URGENT</td>\n",
       "      <td>0.024426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>'MBD001'</td>\n",
       "      <td>0.021406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>'DIG012'</td>\n",
       "      <td>0.021263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>admission_type_DIRECT EMER.</td>\n",
       "      <td>0.021133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>'BLD004'</td>\n",
       "      <td>0.020516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>'SYM002'</td>\n",
       "      <td>0.019465</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              feature  importance_rmse_increase\n",
       "470     admission_type_EU OBSERVATION                  0.061468\n",
       "364                          'NEO060'                  0.059976\n",
       "33                           'END008'                  0.050130\n",
       "4                            'EXT025'                  0.031591\n",
       "75                           'RSP012'                  0.030544\n",
       "94                           'NVS020'                  0.029725\n",
       "134                          'INF002'                  0.028008\n",
       "218                          'BLD010'                  0.026619\n",
       "481  admission_location_Unknown/Other                  0.026128\n",
       "474             admission_type_URGENT                  0.024426\n",
       "117                          'MBD001'                  0.021406\n",
       "156                          'DIG012'                  0.021263\n",
       "467       admission_type_DIRECT EMER.                  0.021133\n",
       "12                           'BLD004'                  0.020516\n",
       "250                          'SYM002'                  0.019465"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 29 - Feature importance for leangth of stay (Permutation Importance)\n",
    "# Compute baseline RMSE and estimate feature importance for LoS using permutation based RMSE increase\n",
    "_, baseline_rmse, _, _ = eval_los(test_los_loader)\n",
    "\n",
    "# Apply permutation importance to rank LoS features by increase in RMSE\n",
    "feature_importance_los = permutation_importance_lstm_regression(\n",
    "    model=los_model,\n",
    "    loader=test_los_loader,\n",
    "    feature_cols=los_feature_cols,\n",
    "    baseline_rmse=baseline_rmse\n",
    ")\n",
    "\n",
    "feature_importance_los.head(15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 30 - data preparation (objective 3)\n",
    "# Build race aware LoS test sequences and DataLoader for subgroup (fairness) evaluation\n",
    "Xte_los_r, yte_los_r, Lte_los_r, race_te_los = build_los_sequences_with_race(test)\n",
    "\n",
    "test_los_race_loader = DataLoader(\n",
    "    LoSDatasetRace(Xte_los_r, yte_los_r, Lte_los_r, race_te_los),\n",
    "    batch_size=64, shuffle=False, collate_fn=los_collate_fn_race\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 30.5 - data preparation (objective 3)\n",
    "# Evaluate LoS regression performance by race using regression metrics for fairness analysis\n",
    "@torch.no_grad()\n",
    "def eval_los_by_race(loader):\n",
    "    los_model.eval()\n",
    "    buckets = {}  # race -> list of (y_true, y_pred)\n",
    "\n",
    "    for X_pad, y_pad, lengths, races in loader:\n",
    "        X_pad = X_pad.to(device)\n",
    "        y_pad = y_pad.to(device)\n",
    "\n",
    "        preds = los_model(X_pad, lengths).detach().cpu().numpy()\n",
    "        y_full = y_pad.detach().cpu().numpy()\n",
    "\n",
    "        for i, race in enumerate(races):\n",
    "            T = lengths[i].item()\n",
    "            true = y_full[i, :T]\n",
    "            pred = preds[i, :T]\n",
    "            good = (true != -1)\n",
    "            true = true[good]\n",
    "            pred = pred[good]\n",
    "            if len(true) == 0:\n",
    "                continue\n",
    "            buckets.setdefault(race, []).append((true, pred))\n",
    "\n",
    "     # Aggregate race wise predictions and compute regression metrics\n",
    "    rows = []\n",
    "    for race, lst in buckets.items():\n",
    "        y_true = np.concatenate([t for t, _ in lst])\n",
    "        y_pred = np.concatenate([p for _, p in lst])\n",
    "\n",
    "        mse  = np.mean((y_pred - y_true) ** 2)\n",
    "        rmse = np.sqrt(mse)\n",
    "        mae  = np.mean(np.abs(y_pred - y_true))\n",
    "        r2   = (1 - np.sum((y_true - y_pred) ** 2) / np.sum((y_true - np.mean(y_true)) ** 2)) if np.unique(y_true).size > 1 else np.nan\n",
    "\n",
    "        rows.append((race, len(lst), mse, rmse, mae, r2))\n",
    "\n",
    "    # Return race wise LoS performance table sorted by group size\n",
    "    out = pd.DataFrame(rows, columns=[\"race_group\", \"n_patients\", \"MSE\", \"RMSE\", \"MAE\", \"R2\"])\n",
    "    return out.sort_values([\"n_patients\"], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 362
    },
    "id": "etdLw3EX2knr",
    "outputId": "b519d6a1-8349-4734-c1c3-669b6039d031"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>race_group</th>\n",
       "      <th>n_patients</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>race_WHITE</td>\n",
       "      <td>637</td>\n",
       "      <td>0.962912</td>\n",
       "      <td>0.144144</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>0.250980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>race_Unknown/Other</td>\n",
       "      <td>177</td>\n",
       "      <td>0.908612</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.303797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>race_BLACK/AFRICAN AMERICAN</td>\n",
       "      <td>106</td>\n",
       "      <td>0.846756</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>race_ASIAN</td>\n",
       "      <td>19</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>race_HISPANIC OR LATINO</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>race_HISPANIC/LATINO - PUERTO RICAN</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>race_WHITE - RUSSIAN</td>\n",
       "      <td>11</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>race_HISPANIC/LATINO - DOMINICAN</td>\n",
       "      <td>10</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>race_BLACK/CAPE VERDEAN</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>race_ASIAN - CHINESE</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            race_group  n_patients       AUC  Precision  \\\n",
       "0                           race_WHITE         637  0.962912   0.144144   \n",
       "2                   race_Unknown/Other         177  0.908612   0.187500   \n",
       "1          race_BLACK/AFRICAN AMERICAN         106  0.846756   0.080000   \n",
       "4                           race_ASIAN          19  0.933333   0.250000   \n",
       "3              race_HISPANIC OR LATINO          13       NaN   0.000000   \n",
       "6  race_HISPANIC/LATINO - PUERTO RICAN          11       NaN   0.000000   \n",
       "8                 race_WHITE - RUSSIAN          11  1.000000   1.000000   \n",
       "7     race_HISPANIC/LATINO - DOMINICAN          10  1.000000   0.333333   \n",
       "5              race_BLACK/CAPE VERDEAN           9       NaN   0.000000   \n",
       "9                 race_ASIAN - CHINESE           7       NaN   0.000000   \n",
       "\n",
       "     Recall        F1  \n",
       "0  0.969697  0.250980  \n",
       "2  0.800000  0.303797  \n",
       "1  0.666667  0.142857  \n",
       "4  1.000000  0.400000  \n",
       "3  0.000000  0.000000  \n",
       "6  0.000000  0.000000  \n",
       "8  1.000000  1.000000  \n",
       "7  1.000000  0.500000  \n",
       "5  0.000000  0.000000  \n",
       "9  0.000000  0.000000  "
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 31 — Ethnicity/race-wise performance table for mortality (Objective #3)\n",
    "# Computes race wise evaluation metrics on the test set and displays the first 20 rows\n",
    "race_table = eval_by_race(test_loader)\n",
    "race_table.head(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>race_group</th>\n",
       "      <th>n_patients</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>race_WHITE</td>\n",
       "      <td>637</td>\n",
       "      <td>33.640736</td>\n",
       "      <td>5.800064</td>\n",
       "      <td>3.068146</td>\n",
       "      <td>0.365870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>race_Unknown/Other</td>\n",
       "      <td>177</td>\n",
       "      <td>68.410522</td>\n",
       "      <td>8.271066</td>\n",
       "      <td>3.449459</td>\n",
       "      <td>0.298246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>race_BLACK/AFRICAN AMERICAN</td>\n",
       "      <td>106</td>\n",
       "      <td>10.490003</td>\n",
       "      <td>3.238827</td>\n",
       "      <td>2.004642</td>\n",
       "      <td>0.209326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>race_ASIAN</td>\n",
       "      <td>19</td>\n",
       "      <td>47.261982</td>\n",
       "      <td>6.874735</td>\n",
       "      <td>2.719634</td>\n",
       "      <td>0.090853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>race_HISPANIC OR LATINO</td>\n",
       "      <td>13</td>\n",
       "      <td>2.752943</td>\n",
       "      <td>1.659199</td>\n",
       "      <td>1.056369</td>\n",
       "      <td>0.757309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>race_HISPANIC/LATINO - PUERTO RICAN</td>\n",
       "      <td>11</td>\n",
       "      <td>44.561951</td>\n",
       "      <td>6.675474</td>\n",
       "      <td>4.189639</td>\n",
       "      <td>-0.161054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>race_WHITE - RUSSIAN</td>\n",
       "      <td>11</td>\n",
       "      <td>1.493890</td>\n",
       "      <td>1.222248</td>\n",
       "      <td>0.969025</td>\n",
       "      <td>0.799680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>race_HISPANIC/LATINO - DOMINICAN</td>\n",
       "      <td>10</td>\n",
       "      <td>11.954882</td>\n",
       "      <td>3.457583</td>\n",
       "      <td>2.583812</td>\n",
       "      <td>-0.431717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>race_BLACK/CAPE VERDEAN</td>\n",
       "      <td>9</td>\n",
       "      <td>2.926768</td>\n",
       "      <td>1.710780</td>\n",
       "      <td>1.217146</td>\n",
       "      <td>-0.000466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>race_ASIAN - CHINESE</td>\n",
       "      <td>7</td>\n",
       "      <td>16.450153</td>\n",
       "      <td>4.055879</td>\n",
       "      <td>2.853682</td>\n",
       "      <td>-0.095940</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            race_group  n_patients        MSE      RMSE  \\\n",
       "0                           race_WHITE         637  33.640736  5.800064   \n",
       "2                   race_Unknown/Other         177  68.410522  8.271066   \n",
       "1          race_BLACK/AFRICAN AMERICAN         106  10.490003  3.238827   \n",
       "4                           race_ASIAN          19  47.261982  6.874735   \n",
       "3              race_HISPANIC OR LATINO          13   2.752943  1.659199   \n",
       "6  race_HISPANIC/LATINO - PUERTO RICAN          11  44.561951  6.675474   \n",
       "8                 race_WHITE - RUSSIAN          11   1.493890  1.222248   \n",
       "7     race_HISPANIC/LATINO - DOMINICAN          10  11.954882  3.457583   \n",
       "5              race_BLACK/CAPE VERDEAN           9   2.926768  1.710780   \n",
       "9                 race_ASIAN - CHINESE           7  16.450153  4.055879   \n",
       "\n",
       "        MAE        R2  \n",
       "0  3.068146  0.365870  \n",
       "2  3.449459  0.298246  \n",
       "1  2.004642  0.209326  \n",
       "4  2.719634  0.090853  \n",
       "3  1.056369  0.757309  \n",
       "6  4.189639 -0.161054  \n",
       "8  0.969025  0.799680  \n",
       "7  2.583812 -0.431717  \n",
       "5  1.217146 -0.000466  \n",
       "9  2.853682 -0.095940  "
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 32 — Ethnicity/race-wise performance table for LoS (Objective #3)\n",
    "# Computes race wise regression metrics for LoS prediction on the test set\n",
    "\n",
    "los_race_table = eval_los_by_race(test_los_race_loader)\n",
    "los_race_table.head(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
