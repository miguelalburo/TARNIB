{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "rBvfs9rGz_-H"
   },
   "outputs": [],
   "source": [
    "# --- Notebook: LSTM for longitudinal admissions (Module 3) ---\n",
    "# Train: predict hospital_expire_flag per admission sequence (many-to-many)\n",
    "# Notes:\n",
    "# - Uses subject-level split (already done)\n",
    "# - Orders by admission_no (per patient)\n",
    "# - Drops leakage: deathtime, days_until_death (+ dod if exists)\n",
    "# - Excludes race_* from model input (kept for subgroup evaluation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2ok5UF4q0BkA",
    "outputId": "90fa0105-0f5c-42af-ee8a-bafaf47a4457"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 1 — Imports + Reproducibility\n",
    "# Core python and data handling libraries for randomness control, numerical computation and tabular data\n",
    "import os, random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# PyTorch core modules for building neural netowrks (nn), handling datasets and managing the variables sequences length\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "# Use Scikit-learn utilities for feature scaling and model performance evaluation\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score, precision_recall_fscore_support\n",
    "\n",
    "# Set a fixed random seed across the libraries to ensure reproducibilty of results\n",
    "SEED = 67\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# Select the computation device (GPU if available, otherwise CPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6blGOANA0tKH",
    "outputId": "32df2621-b4df-4ca2-eeca-40355ea228d1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((9388, 81), (2430, 81))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 2 — Load CSVs\n",
    "# Define the file paths for the training and testing datasets\n",
    "train_path = \"/jupyter/work/module3/group_project/TARNIB/data/train.csv\"\n",
    "test_path  = \"/jupyter/work/module3/group_project/TARNIB/data/test.csv\"\n",
    "\n",
    "# Load the csv files into panda dataframes\n",
    "train = pd.read_csv(train_path)\n",
    "test = pd.read_csv(test_path)\n",
    "\n",
    "# Display the datasets dimensions (for sanity check)\n",
    "train.shape, test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1_Mmuw_H0-H2",
    "outputId": "a3fa11a2-4f45-4236-c1f3-2e25136ba486"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 3 — Mandatory split sanity check (no subject overlap)\n",
    "# Check that no patient subject_id appears in both the training and testing datasets\n",
    "overlap = len(set(train[\"subject_id\"]) & set(test[\"subject_id\"]))\n",
    "overlap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OYHYJeUY1Bk8",
    "outputId": "a41e338d-77bc-45c5-992f-998176b8923b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped leakage: ['days_until_death']\n"
     ]
    }
   ],
   "source": [
    "# Cell 4 — Drop leakage columns (MUST)\n",
    "# Identify the future related columns that would cause data leakage if used as predictors\n",
    "LEAK = [c for c in [\"deathtime\", \"dod\", \"days_until_death\", \"discharge_location_CHRONIC/LONG TERM ACUTE CARE\",\n",
    "                    \"discharge_location_DIED\", \"discharge_location_HOME\", \"discharge_location_HOME HEALTH CARE\",\n",
    "                    \"discharge_location_Other_discharge_location\", \"discharge_location_REHAB\",\n",
    "                    \"discharge_location_SKILLED NURSING FACILITY\", \"discharge_location_Unknown_discharge_location\"]\n",
    "        if c in train.columns]\n",
    "\n",
    "# Remove the leakage columns from both training and testing datasets\n",
    "train = train.drop(columns=LEAK)\n",
    "test  = test.drop(columns=LEAK)\n",
    "print(\"Dropped leakage:\", LEAK)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rMSqnoWD1SqM",
    "outputId": "d5ff86c7-4579-4665-ed06-fbdc228443a4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10,\n",
       " ['race_ASIAN',\n",
       "  'race_ASIAN - CHINESE',\n",
       "  'race_BLACK/AFRICAN AMERICAN',\n",
       "  'race_BLACK/CAPE VERDEAN',\n",
       "  'race_HISPANIC OR LATINO'])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 5 — Basic column roles\n",
    "# Define the identifiers, ordering and target columns used throughout the pipeline\n",
    "ID_COLS    = [\"subject_id\", \"hadm_id\"]\n",
    "ORDER_COL  = \"admission_no\"          # sorting only\n",
    "Y_COL      = \"hospital_expire_flag\"  # target\n",
    "\n",
    "# Identify Race indicator columns for subgroup evaluation only (not used as predictors)\n",
    "race_cols = [c for c in train.columns if c.startswith(\"race_\")]\n",
    "len(race_cols), race_cols[:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 240
    },
    "id": "PFgrDOJz1XlM",
    "outputId": "56fbd902-0bcf-4c51-bde4-9df234ba63ca"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    1\n",
       "2    1\n",
       "3    1\n",
       "4    0\n",
       "Name: gender, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 6 — Encode gender if needed (M/F -> 1/0)\n",
    "# define a function to convert categorical gender variable into a numeric format if applicable\n",
    "def encode_gender(df):\n",
    "    if \"gender\" in df.columns and df[\"gender\"].dtype == object:\n",
    "        df[\"gender\"] = df[\"gender\"].map({\"M\": 1, \"F\": 0}).astype(\"float32\")\n",
    "    return df\n",
    "\n",
    "# Apply gender encoding to both the training and testing datasets\n",
    "train = encode_gender(train)\n",
    "test  = encode_gender(test)\n",
    "\n",
    "# Inspect the encoded gender values to ensure successful transofmration\n",
    "train[\"gender\"].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hRVQ2jun1bVF",
    "outputId": "a66c4296-c352-4056-d233-1c761dacc608"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(65,\n",
       " ['gender',\n",
       "  'age',\n",
       "  'ER_LoS',\n",
       "  'days_since_discharge',\n",
       "  'admission_type_AMBULATORY OBSERVATION',\n",
       "  'admission_type_DIRECT EMER.',\n",
       "  'admission_type_DIRECT OBSERVATION',\n",
       "  'admission_type_ELECTIVE',\n",
       "  'admission_type_EU OBSERVATION',\n",
       "  'admission_type_EW EMER.',\n",
       "  'admission_type_OBSERVATION ADMIT',\n",
       "  'admission_type_SURGICAL SAME DAY ADMISSION',\n",
       "  'admission_type_URGENT',\n",
       "  'admission_location_CLINIC REFERRAL',\n",
       "  'admission_location_EMERGENCY ROOM'])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 7 — Define feature columns (exclude IDs, order, label, race_*)\n",
    "# Specify the columns to exclude model inputs\n",
    "drop_from_X = set(ID_COLS + [ORDER_COL, Y_COL]) | set(race_cols) | {\"LoS\"}\n",
    "feature_cols = [c for c in train.columns if c not in drop_from_X]\n",
    "\n",
    "# Check the number of selected features and preview a subset of them\n",
    "len(feature_cols), feature_cols[:15]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 178
    },
    "id": "g3zOTAjg1vOF",
    "outputId": "a33c571b-ede7-4c3f-ebfa-11683b4a07be"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>ER_LoS</th>\n",
       "      <th>days_since_discharge</th>\n",
       "      <th>admission_type_AMBULATORY OBSERVATION</th>\n",
       "      <th>admission_type_DIRECT EMER.</th>\n",
       "      <th>admission_type_DIRECT OBSERVATION</th>\n",
       "      <th>admission_type_ELECTIVE</th>\n",
       "      <th>admission_type_EU OBSERVATION</th>\n",
       "      <th>admission_type_EW EMER.</th>\n",
       "      <th>...</th>\n",
       "      <th>ccs_emb_21</th>\n",
       "      <th>ccs_emb_22</th>\n",
       "      <th>ccs_emb_23</th>\n",
       "      <th>ccs_emb_24</th>\n",
       "      <th>ccs_emb_25</th>\n",
       "      <th>ccs_emb_26</th>\n",
       "      <th>ccs_emb_27</th>\n",
       "      <th>ccs_emb_28</th>\n",
       "      <th>ccs_emb_29</th>\n",
       "      <th>ccs_emb_30</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      gender  age  ER_LoS  days_since_discharge  \\\n",
       "mean     0.0  0.0    -0.0                  -0.0   \n",
       "std      1.0  1.0     1.0                   1.0   \n",
       "\n",
       "      admission_type_AMBULATORY OBSERVATION  admission_type_DIRECT EMER.  \\\n",
       "mean                                    0.0                          0.0   \n",
       "std                                     1.0                          1.0   \n",
       "\n",
       "      admission_type_DIRECT OBSERVATION  admission_type_ELECTIVE  \\\n",
       "mean                               -0.0                      0.0   \n",
       "std                                 1.0                      1.0   \n",
       "\n",
       "      admission_type_EU OBSERVATION  admission_type_EW EMER.  ...  ccs_emb_21  \\\n",
       "mean                            0.0                     -0.0  ...        -0.0   \n",
       "std                             1.0                      1.0  ...         1.0   \n",
       "\n",
       "      ccs_emb_22  ccs_emb_23  ccs_emb_24  ccs_emb_25  ccs_emb_26  ccs_emb_27  \\\n",
       "mean         0.0        -0.0        -0.0         0.0         0.0         0.0   \n",
       "std          1.0         1.0         1.0         1.0         1.0         1.0   \n",
       "\n",
       "      ccs_emb_28  ccs_emb_29  ccs_emb_30  \n",
       "mean         0.0         0.0         0.0  \n",
       "std          1.0         1.0         1.0  \n",
       "\n",
       "[2 rows x 65 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 8 — Impute missing values (train medians) + scale (fit on train only)\n",
    "# Handle missing values using the training set median\n",
    "train_medians = train[feature_cols].median(numeric_only=True)\n",
    "train[feature_cols] = train[feature_cols].fillna(train_medians)\n",
    "test[feature_cols]  = test[feature_cols].fillna(train_medians)\n",
    "\n",
    "# Fit feature scaler on training data only and apply to both datasets to avoid leakage\n",
    "scaler = StandardScaler()\n",
    "train[feature_cols] = scaler.fit_transform(train[feature_cols])\n",
    "test[feature_cols]  = scaler.transform(test[feature_cols])\n",
    "\n",
    "# Verifying the scaling (sanity check) by checking the features means and sd\n",
    "train[feature_cols].describe().loc[[\"mean\",\"std\"]].round(3).head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yhp5r58f130z",
    "outputId": "3fa328cc-484c-4091-9a73-29ab34c1030a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4000, 1000, 1, 101)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 9 — Sequence builder helpers\n",
    "# A function to derive a single race label per subject (for subgroup evaluation) and to convert tabular rows into per-subjects sequences\n",
    "def infer_race_label(row, race_cols):\n",
    "    if not race_cols:\n",
    "        return \"NO_RACE_COLS\"\n",
    "    vals = row[race_cols].to_numpy()\n",
    "    if np.all(np.isnan(vals)) or np.all(vals == 0):\n",
    "        return \"race_UNKNOWN\"\n",
    "    return race_cols[int(np.argmax(vals))]\n",
    "\n",
    "# A function to build variable length per subject_id: X is (T,F), y is (T,), and lengths store T for packing/padding later\n",
    "def build_sequences(df: pd.DataFrame):\n",
    "    # sort within patient\n",
    "    df = df.sort_values([\"subject_id\", ORDER_COL])\n",
    "\n",
    "    X_list, y_list, lengths, race_list = [], [], [], []\n",
    "\n",
    "    # Build subject_id level admission sequences (features, labels, lengths, race)\n",
    "    for sid, g in df.groupby(\"subject_id\", sort=False):\n",
    "        X = torch.tensor(g[feature_cols].to_numpy(np.float32))           # (T, F)\n",
    "        y = torch.tensor(g[Y_COL].to_numpy(np.float32))                  # (T,)\n",
    "        X_list.append(X)\n",
    "        y_list.append(y)\n",
    "        lengths.append(len(g))\n",
    "\n",
    "        if race_cols:\n",
    "            race_list.append(infer_race_label(g.iloc[0], race_cols))\n",
    "        else:\n",
    "            race_list.append(\"NO_RACE_COLS\")\n",
    "\n",
    "    lengths = torch.tensor(lengths, dtype=torch.long)\n",
    "    return X_list, y_list, lengths, race_list\n",
    "\n",
    "# Build train/test sequence lists (one sequence per subject) + lenght for later packing\n",
    "Xtr_list, ytr_list, Ltr, race_tr = build_sequences(train)\n",
    "Xte_list, yte_list, Lte, race_te = build_sequences(test)\n",
    "\n",
    "# Display number of subjects (sanity check) and number of admissions per subject\n",
    "len(Xtr_list), len(Xte_list), Ltr.min().item(), Ltr.max().item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "7AXa5sor2AgW"
   },
   "outputs": [],
   "source": [
    "# Cell 10 — Dataset + collate (pads sequences)\n",
    "# A custom dataset class to store per-subject sequences, labels, sequence lengths and race metadata\n",
    "class SeqDataset(Dataset):\n",
    "    def __init__(self, X_list, y_list, lengths, race_list):\n",
    "        self.X = X_list\n",
    "        self.y = y_list\n",
    "        self.lengths = lengths\n",
    "        self.race = race_list\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx], self.lengths[idx], self.race[idx]\n",
    "\n",
    "# A custom collate function to pad variable length sequences within each batch\n",
    "def collate_fn(batch):\n",
    "    Xs, ys, lens, races = zip(*batch)\n",
    "    X_pad = pad_sequence(Xs, batch_first=True)                 # (B, T, F)\n",
    "    y_pad = pad_sequence(ys, batch_first=True, padding_value=-1.0)  # (B, T)\n",
    "    lens  = torch.tensor(lens, dtype=torch.long)\n",
    "    return X_pad, y_pad, lens, list(races)\n",
    "\n",
    "# To instantiate dataset objects for training and testing data\n",
    "train_ds = SeqDataset(Xtr_list, ytr_list, Ltr.tolist(), race_tr)\n",
    "test_ds  = SeqDataset(Xte_list, yte_list, Lte.tolist(), race_te)\n",
    "\n",
    "# Create dataloaders to generate padded mimi batches during training and evaluation\n",
    "BATCH_SIZE = 64\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True,  collate_fn=collate_fn)\n",
    "test_loader  = DataLoader(test_ds,  batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WXsN_eqG2GCO",
    "outputId": "8e003d4a-4548-44f9-a79d-a5db89cf7001"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTMSeq(\n",
       "  (lstm): LSTM(65, 64, batch_first=True)\n",
       "  (fc): Linear(in_features=64, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 11 — LSTM model (many-to-many logits: one per timestep)\n",
    "# Define an LSTM-based sequence model that outputs a prediction at each timestep\n",
    "class LSTMSeq(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim=64, num_layers=1, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_dim,\n",
    "            hidden_size=hidden_dim,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            dropout=dropout if num_layers > 1 else 0.0\n",
    "        )\n",
    "        self.fc = nn.Linear(hidden_dim, 1)\n",
    "\n",
    "# Define a Forward pass that handle padded sequences and produce per timestep logits\n",
    "    def forward(self, x, lengths):\n",
    "        packed = pack_padded_sequence(x, lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
    "        packed_out, _ = self.lstm(packed)\n",
    "        out, _ = pad_packed_sequence(packed_out, batch_first=True)  # (B, T, H)\n",
    "        logits = self.fc(out).squeeze(-1)                           # (B, T)\n",
    "        return logits\n",
    "\n",
    "# Instantiate the LSTM model and move it to the selected device\n",
    "model = LSTMSeq(input_dim=len(feature_cols), hidden_dim=64, num_layers=1, dropout=0.0).to(device)\n",
    "model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QOiNGMki2KDE",
    "outputId": "b5042edc-9b49-4d74-a277-828e1331d3f1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(219, 9169, 41.86758041381836)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 12 — Loss with class imbalance (pos_weight) + masked timesteps\n",
    "# Compute class imbalance from training labels to weight the positive class during loss calculation\n",
    "y_flat = np.concatenate([y.numpy() for y in ytr_list])\n",
    "pos = (y_flat == 1).sum()\n",
    "neg = (y_flat == 0).sum()\n",
    "\n",
    "# Define positive class weight (neg/pos) for use in weighted binary cross-entropy\n",
    "pos_weight = torch.tensor([neg / max(pos, 1)], dtype=torch.float32).to(device)\n",
    "pos, neg, pos_weight.item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "tVWZNX3T2PM1"
   },
   "outputs": [],
   "source": [
    "# Cell 13 — Train/eval utilities\n",
    "# Define weighted BCE loss (handles class imbalance) and Adam optimiser for training\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# Compute BCE loss while ignoring padded timesteps (label == -1)\n",
    "def masked_bce_loss(logits, y):\n",
    "    # y has padding -1\n",
    "    mask = (y != -1)\n",
    "    return criterion(logits[mask], y[mask])\n",
    "\n",
    "# Evaluate overall performance on a DataLoader (AUC, Precision, Recall, F1) using only real timesteps\n",
    "@torch.no_grad() # Disables gradient tracking, Makes evaluation faster & uses less memory\n",
    "def eval_loader(loader):\n",
    "    model.eval()\n",
    "    all_probs, all_true = [], []\n",
    "\n",
    "    for X_pad, y_pad, lengths, _races in loader:\n",
    "        X_pad = X_pad.to(device)\n",
    "        y_pad = y_pad.to(device)\n",
    "        logits = model(X_pad, lengths)\n",
    "        mask = (y_pad != -1)\n",
    "\n",
    "        probs = torch.sigmoid(logits[mask]).detach().cpu().numpy()\n",
    "        true  = y_pad[mask].detach().cpu().numpy()\n",
    "\n",
    "        all_probs.append(probs)\n",
    "        all_true.append(true)\n",
    "\n",
    "#\n",
    "    probs = np.concatenate(all_probs) if all_probs else np.array([])\n",
    "    true  = np.concatenate(all_true)  if all_true  else np.array([])\n",
    "\n",
    "    auc = roc_auc_score(true, probs) if len(np.unique(true)) > 1 else np.nan\n",
    "    pred = (probs >= 0.5).astype(int)\n",
    "\n",
    "    p, r, f1, _ = precision_recall_fscore_support(true, pred, average=\"binary\", zero_division=0)\n",
    "    return {\"AUC\": auc, \"Precision\": p, \"Recall\": r, \"F1\": f1}\n",
    "\n",
    "# Evaluate performance by race group (Objective 3) by aggregating admission level predictions per patient race label\n",
    "@torch.no_grad()\n",
    "def eval_by_race(loader):\n",
    "    # aggregates admission-level predictions by patient race label\n",
    "    model.eval()\n",
    "    buckets = {}  # race -> list of (true, prob)\n",
    "\n",
    "    for X_pad, y_pad, lengths, races in loader:\n",
    "        X_pad = X_pad.to(device)\n",
    "        y_pad = y_pad.to(device)\n",
    "        logits = model(X_pad, lengths)\n",
    "        probs_full = torch.sigmoid(logits).detach().cpu().numpy()\n",
    "        y_full     = y_pad.detach().cpu().numpy()\n",
    "\n",
    "        for i, race in enumerate(races):\n",
    "            T = lengths[i].item()\n",
    "            true = y_full[i, :T]\n",
    "            prob = probs_full[i, :T]\n",
    "            good = (true != -1)\n",
    "            true = true[good]\n",
    "            prob = prob[good]\n",
    "            if len(true) == 0:\n",
    "                continue\n",
    "            buckets.setdefault(race, []).append((true, prob))\n",
    "\n",
    "# Compute metrics per race group by concatenating patient level predictions\n",
    "    rows = []\n",
    "    for race, lst in buckets.items():\n",
    "        true = np.concatenate([t for t, _ in lst])\n",
    "        prob = np.concatenate([p for _, p in lst])\n",
    "        if len(np.unique(true)) < 2:\n",
    "            auc = np.nan\n",
    "        else:\n",
    "            auc = roc_auc_score(true, prob)\n",
    "        pred = (prob >= 0.5).astype(int)\n",
    "        p, r, f1, _ = precision_recall_fscore_support(true, pred, average=\"binary\", zero_division=0)\n",
    "        rows.append((race, len(lst), auc, p, r, f1))\n",
    "\n",
    "# Return results as a table sorted by group size\n",
    "    out = pd.DataFrame(rows, columns=[\"race_group\", \"n_patients\", \"AUC\", \"Precision\", \"Recall\", \"F1\"])\n",
    "    return out.sort_values([\"n_patients\"], ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2hSPbHNy2Xg0",
    "outputId": "58c5d10c-dcd7-4259-96ca-b4514d4ae2de"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 | loss=1.2332 | AUC=0.837 P=0.056 R=0.964 F1=0.105\n",
      "Epoch 02 | loss=1.0300 | AUC=0.856 P=0.062 R=0.927 F1=0.117\n",
      "Epoch 03 | loss=0.9001 | AUC=0.863 P=0.071 R=0.927 F1=0.132\n",
      "Epoch 04 | loss=0.7815 | AUC=0.883 P=0.077 R=0.891 F1=0.142\n",
      "Epoch 05 | loss=0.7066 | AUC=0.876 P=0.092 R=0.855 F1=0.167\n",
      "Epoch 06 | loss=0.6274 | AUC=0.880 P=0.093 R=0.873 F1=0.168\n",
      "Epoch 07 | loss=0.5543 | AUC=0.868 P=0.097 R=0.818 F1=0.174\n",
      "Epoch 08 | loss=0.4991 | AUC=0.880 P=0.103 R=0.800 F1=0.183\n",
      "Epoch 09 | loss=0.4646 | AUC=0.877 P=0.112 R=0.709 F1=0.193\n",
      "Early stopping.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8827253588516747"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 14 — Training loop (with simple early stopping on AUC)\n",
    "# Set training hyperparameters and early stopping criteria\n",
    "EPOCHS = 25\n",
    "best_auc = -np.inf\n",
    "patience = 5\n",
    "bad = 0\n",
    "\n",
    "# Main training loop over epochs\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    model.train()\n",
    "    running = 0.0\n",
    "\n",
    "    for X_pad, y_pad, lengths, _races in train_loader:\n",
    "        X_pad = X_pad.to(device)\n",
    "        y_pad = y_pad.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(X_pad, lengths)\n",
    "        loss = masked_bce_loss(logits, y_pad)\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "\n",
    "        running += loss.item()\n",
    "\n",
    "# Evaluate model on test set and report metrics\n",
    "    metrics = eval_loader(test_loader)\n",
    "    avg_loss = running / max(len(train_loader), 1)\n",
    "\n",
    "    print(f\"Epoch {epoch:02d} | loss={avg_loss:.4f} | \"\n",
    "          f\"AUC={metrics['AUC']:.3f} P={metrics['Precision']:.3f} \"\n",
    "          f\"R={metrics['Recall']:.3f} F1={metrics['F1']:.3f}\")\n",
    "\n",
    "    # Save best model and stop training if AUC does not improve\n",
    "    if metrics[\"AUC\"] > best_auc + 1e-4:\n",
    "        best_auc = metrics[\"AUC\"]\n",
    "        bad = 0\n",
    "        torch.save(model.state_dict(), \"best_lstm_mortality.pt\")\n",
    "    else:\n",
    "        bad += 1\n",
    "        if bad >= patience:\n",
    "            print(\"Early stopping.\")\n",
    "            break\n",
    "\n",
    "best_auc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7A1aBDAj2gi_",
    "outputId": "91191db5-246a-4c91-84ed-49bf38217b9f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_85/3805121918.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(\"best_lstm_mortality.pt\", map_location=device))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'AUC': 0.8827253588516747,\n",
       " 'Precision': 0.07740916271721959,\n",
       " 'Recall': 0.8909090909090909,\n",
       " 'F1': 0.14244186046511628}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 15 — Load best model + final evaluation\n",
    "# Load the best performing model checkpoint and evaluate it on the test dataset\n",
    "model.load_state_dict(torch.load(\"best_lstm_mortality.pt\", map_location=device))\n",
    "final_metrics = eval_loader(test_loader)\n",
    "final_metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 362
    },
    "id": "etdLw3EX2knr",
    "outputId": "b519d6a1-8349-4734-c1c3-669b6039d031"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>race_group</th>\n",
       "      <th>n_patients</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>race_WHITE</td>\n",
       "      <td>637</td>\n",
       "      <td>0.901245</td>\n",
       "      <td>0.077670</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>0.143820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>race_Unknown/Other</td>\n",
       "      <td>177</td>\n",
       "      <td>0.849037</td>\n",
       "      <td>0.114035</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.201550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>race_BLACK/AFRICAN AMERICAN</td>\n",
       "      <td>106</td>\n",
       "      <td>0.882550</td>\n",
       "      <td>0.028169</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.054054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>race_ASIAN</td>\n",
       "      <td>19</td>\n",
       "      <td>0.883333</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>race_HISPANIC OR LATINO</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>race_HISPANIC/LATINO - PUERTO RICAN</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>race_WHITE - RUSSIAN</td>\n",
       "      <td>11</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>race_HISPANIC/LATINO - DOMINICAN</td>\n",
       "      <td>10</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>race_BLACK/CAPE VERDEAN</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>race_ASIAN - CHINESE</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            race_group  n_patients       AUC  Precision  \\\n",
       "0                           race_WHITE         637  0.901245   0.077670   \n",
       "2                   race_Unknown/Other         177  0.849037   0.114035   \n",
       "1          race_BLACK/AFRICAN AMERICAN         106  0.882550   0.028169   \n",
       "4                           race_ASIAN          19  0.883333   0.125000   \n",
       "3              race_HISPANIC OR LATINO          13       NaN   0.000000   \n",
       "6  race_HISPANIC/LATINO - PUERTO RICAN          11       NaN   0.000000   \n",
       "8                 race_WHITE - RUSSIAN          11  1.000000   0.500000   \n",
       "7     race_HISPANIC/LATINO - DOMINICAN          10  0.250000   0.000000   \n",
       "5              race_BLACK/CAPE VERDEAN           9       NaN   0.000000   \n",
       "9                 race_ASIAN - CHINESE           7       NaN   0.000000   \n",
       "\n",
       "     Recall        F1  \n",
       "0  0.969697  0.143820  \n",
       "2  0.866667  0.201550  \n",
       "1  0.666667  0.054054  \n",
       "4  0.500000  0.200000  \n",
       "3  0.000000  0.000000  \n",
       "6  0.000000  0.000000  \n",
       "8  1.000000  0.666667  \n",
       "7  0.000000  0.000000  \n",
       "5  0.000000  0.000000  \n",
       "9  0.000000  0.000000  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 16 — Ethnicity/race-wise performance table (Objective #3)\n",
    "# Computes race wise evaluation metrics on the test set and displays the first 20 rows\n",
    "race_table = eval_by_race(test_loader)\n",
    "race_table.head(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wyilE9ch2qHN",
    "outputId": "42f45b6f-865c-419e-e264-e4f14540db3f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: best_lstm_mortality.pt, scaler.joblib, feature_cols.joblib\n"
     ]
    }
   ],
   "source": [
    "# Cell 17 — Save scaler + feature columns (for reproducibility)\n",
    "# joblib library to efficiently save and load Python objects\n",
    "import joblib\n",
    "\n",
    "# Save the fitted scaler and feature column order to disk\n",
    "joblib.dump(scaler, \"scaler.joblib\")\n",
    "joblib.dump(feature_cols, \"feature_cols.joblib\")\n",
    "\n",
    "print(\"Saved: best_lstm_mortality.pt, scaler.joblib, feature_cols.joblib\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 335
    },
    "id": "6T03jY222zF8",
    "outputId": "eed2c707-cf52-4655-f8c8-282a42608980"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    4000.000000\n",
       "mean        2.347000\n",
       "std         3.484268\n",
       "min         1.000000\n",
       "25%         1.000000\n",
       "50%         1.000000\n",
       "75%         2.000000\n",
       "max       101.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 18 — Quick note about sequence lengths\n",
    "# Computes summary statistics of sequence lengths to describe variability in time series duration\n",
    "seq_stats = pd.Series(Ltr.tolist()).describe()\n",
    "seq_stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4fIhRXA_BMR_",
    "outputId": "ce789152-ca71-47e2-9988-ba49dd47c11b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2430, array([1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 19 - extract model predictions on the test set\n",
    "# Generate probability predictions, binary predictions and true labels from the test set\n",
    "@torch.no_grad()\n",
    "def get_test_predictions(loader, threshold=0.5):\n",
    "    model.eval()\n",
    "    all_probs, all_preds, all_true = [], [], []\n",
    "\n",
    "# Iterate through the test DataLoader and collect masked predictions\n",
    "    for X_pad, y_pad, lengths, _ in loader:\n",
    "        X_pad = X_pad.to(device)\n",
    "        y_pad = y_pad.to(device)\n",
    "\n",
    "        logits = model(X_pad, lengths)\n",
    "        probs = torch.sigmoid(logits)\n",
    "\n",
    "        mask = (y_pad != -1)\n",
    "\n",
    "        probs = probs[mask].cpu().numpy()\n",
    "        true  = y_pad[mask].cpu().numpy()\n",
    "        preds = (probs >= threshold).astype(int)\n",
    "\n",
    "        all_probs.append(probs)\n",
    "        all_preds.append(preds)\n",
    "        all_true.append(true)\n",
    "\n",
    "    return (\n",
    "        np.concatenate(all_probs),\n",
    "        np.concatenate(all_preds),\n",
    "        np.concatenate(all_true)\n",
    "    )\n",
    "\n",
    "# Run prediction function on the test set and inspect output size and first predictions\n",
    "test_probs, test_preds, test_true = get_test_predictions(test_loader)\n",
    "\n",
    "len(test_preds), test_preds[:20]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XcYRressBNzr",
    "outputId": "5f363a38-089b-4e66-931d-09e0874a4460"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1791,  584],\n",
       "       [   6,   49]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 20 - summarize classification performance on the test set\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Generate confusion matrix from true and predicted test labels\n",
    "cm = confusion_matrix(test_true, test_preds)\n",
    "cm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 407
    },
    "id": "dQa16fAoBQ5l",
    "outputId": "10998f72-9b42-448d-b4ac-dfcde8ba7893"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cell 21 - Visualize the confusion matrix as a heatmap\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Plot the confusion matrix with annotations and labeled axes\n",
    "plt.figure(figsize=(5,4))\n",
    "sns.heatmap(\n",
    "    cm,\n",
    "    annot=True,\n",
    "    fmt=\"d\",\n",
    "    cmap=\"Blues\",\n",
    "    xticklabels=[\"Predicted 0\", \"Predicted 1\"],\n",
    "    yticklabels=[\"Actual 0\", \"Actual 1\"]\n",
    ")\n",
    "plt.title(\"Confusion Matrix — LSTM Mortality Prediction\")\n",
    "plt.ylabel(\"True label\")\n",
    "plt.xlabel(\"Predicted label\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "0emnWnj2nvMF"
   },
   "outputs": [],
   "source": [
    "# Cell 21.5A — Define permutation importance for LSTM (classification)\n",
    "# Define a function that shuffles one feature at a time and measures the resulting AUC drop\n",
    "@torch.no_grad()\n",
    "def permutation_importance_lstm(\n",
    "    model, loader, feature_cols, baseline_auc, n_repeats=1\n",
    "):\n",
    "    model.eval()\n",
    "    importances = []\n",
    "\n",
    "# Loop over each feature and measure AUC drop when that feature is shuffled\n",
    "    for j, feat in enumerate(feature_cols):\n",
    "        drops = []\n",
    "\n",
    "        for _ in range(n_repeats):\n",
    "            all_probs, all_true = [], []\n",
    "\n",
    "            for X_pad, y_pad, lengths, _ in loader:\n",
    "                X_pad = X_pad.clone()\n",
    "                y_pad = y_pad.to(device)\n",
    "\n",
    "                # shuffle feature j\n",
    "                vals = X_pad[:, :, j].cpu().numpy().flatten()\n",
    "                np.random.shuffle(vals)\n",
    "                X_pad[:, :, j] = torch.tensor(\n",
    "                    vals.reshape(X_pad[:, :, j].shape),\n",
    "                    dtype=X_pad.dtype\n",
    "                )\n",
    "\n",
    "                X_pad = X_pad.to(device)\n",
    "                logits = model(X_pad, lengths)\n",
    "                mask = (y_pad != -1)\n",
    "\n",
    "                probs = torch.sigmoid(logits[mask]).cpu().numpy()\n",
    "                true  = y_pad[mask].cpu().numpy()\n",
    "\n",
    "                all_probs.append(probs)\n",
    "                all_true.append(true)\n",
    "\n",
    "            probs = np.concatenate(all_probs)\n",
    "            true  = np.concatenate(all_true)\n",
    "\n",
    "            auc = roc_auc_score(true, probs) if len(np.unique(true)) > 1 else np.nan\n",
    "            drops.append(baseline_auc - auc)\n",
    "\n",
    "        importances.append(np.nanmean(drops))\n",
    "\n",
    "# Return ranked feature importances as mean AUC drop after shuffling each feature\n",
    "    return pd.DataFrame({\n",
    "        \"feature\": feature_cols,\n",
    "        \"importance_auc_drop\": importances\n",
    "    }).sort_values(\"importance_auc_drop\", ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 519
    },
    "id": "XVvKefebml8j",
    "outputId": "fd1bf292-3f95-4610-8c56-54db703023a1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance_auc_drop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>age</td>\n",
       "      <td>0.019621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>admission_type_EW EMER.</td>\n",
       "      <td>0.013359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>ccs_emb_23</td>\n",
       "      <td>0.009914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>ccs_emb_4</td>\n",
       "      <td>0.008949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>admission_type_EU OBSERVATION</td>\n",
       "      <td>0.006668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>language_Chinese</td>\n",
       "      <td>0.005458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ER_LoS</td>\n",
       "      <td>0.004134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>admission_location_Unknown/Other</td>\n",
       "      <td>0.004096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>ccs_emb_11</td>\n",
       "      <td>0.003897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>ccs_emb_1</td>\n",
       "      <td>0.003414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>ccs_emb_8</td>\n",
       "      <td>0.003353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>ccs_emb_27</td>\n",
       "      <td>0.003322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>ccs_emb_22</td>\n",
       "      <td>0.003208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>admission_type_AMBULATORY OBSERVATION</td>\n",
       "      <td>0.003055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>ccs_emb_25</td>\n",
       "      <td>0.002909</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  feature  importance_auc_drop\n",
       "1                                     age             0.019621\n",
       "9                 admission_type_EW EMER.             0.013359\n",
       "57                             ccs_emb_23             0.009914\n",
       "38                              ccs_emb_4             0.008949\n",
       "8           admission_type_EU OBSERVATION             0.006668\n",
       "25                       language_Chinese             0.005458\n",
       "2                                  ER_LoS             0.004134\n",
       "19       admission_location_Unknown/Other             0.004096\n",
       "45                             ccs_emb_11             0.003897\n",
       "35                              ccs_emb_1             0.003414\n",
       "42                              ccs_emb_8             0.003353\n",
       "61                             ccs_emb_27             0.003322\n",
       "56                             ccs_emb_22             0.003208\n",
       "4   admission_type_AMBULATORY OBSERVATION             0.003055\n",
       "59                             ccs_emb_25             0.002909"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 21.5B — Feature importance for mortality (Permutation Importance)\n",
    "# Compute baseline AUC and estimate feature importance using permutation based AUC drop\n",
    "baseline_auc = eval_loader(test_loader)[\"AUC\"]\n",
    "\n",
    "# Apply permutation importance to rank features by their impact on mortality prediction\n",
    "feature_importance_mortality = permutation_importance_lstm(\n",
    "    model=model,\n",
    "    loader=test_loader,\n",
    "    feature_cols=feature_cols,   # mortality feature set (LoS excluded)\n",
    "    baseline_auc=baseline_auc,\n",
    "    n_repeats=1\n",
    ")\n",
    "\n",
    "feature_importance_mortality.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sHcQeDuRC-OH",
    "outputId": "0169431b-9bf4-4c31-c0ad-af4a9eba159a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 22 — Define LoS regression target\n",
    "LOS_COL = \"LoS\"\n",
    "\n",
    "# Feature columns for LoS prediction (remove LoS itself)\n",
    "los_feature_cols = [c for c in feature_cols if c != LOS_COL]\n",
    "\n",
    "len(los_feature_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "ipqqPGTxDEs_"
   },
   "outputs": [],
   "source": [
    "# Cell 23 — Build LoS sequences (many-to-many regression)\n",
    "# Construct per subject variable length input and target sequences for LoS regression\n",
    "def build_los_sequences(df: pd.DataFrame):\n",
    "    df = df.sort_values([\"subject_id\", ORDER_COL])\n",
    "\n",
    "    X_list, y_list, lengths = [], [], []\n",
    "\n",
    "    for _, g in df.groupby(\"subject_id\", sort=False):\n",
    "        X = torch.tensor(g[los_feature_cols].to_numpy(np.float32))   # (T, F)\n",
    "        y = torch.tensor(g[LOS_COL].to_numpy(np.float32))            # (T,)\n",
    "        X_list.append(X)\n",
    "        y_list.append(y)\n",
    "        lengths.append(len(g))\n",
    "\n",
    "    return X_list, y_list, torch.tensor(lengths, dtype=torch.long)\n",
    "\n",
    "# Build LoS input target sequences for training and test datasets\n",
    "Xtr_los, ytr_los, Ltr_los = build_los_sequences(train)\n",
    "Xte_los, yte_los, Lte_los = build_los_sequences(test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "ffyMRjYxDI6-"
   },
   "outputs": [],
   "source": [
    "# Cell 24 — DataLoaders for LoS regression\n",
    "# Define dataset and collate function to handle variable-length LoS sequences\n",
    "class LoSDataset(Dataset):\n",
    "    def __init__(self, X_list, y_list, lengths):\n",
    "        self.X = X_list\n",
    "        self.y = y_list\n",
    "        self.lengths = lengths\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx], self.lengths[idx]\n",
    "\n",
    "# Pad variable length input and target sequences for batching\n",
    "def los_collate_fn(batch):\n",
    "    Xs, ys, lens = zip(*batch)\n",
    "    X_pad = pad_sequence(Xs, batch_first=True)\n",
    "    y_pad = pad_sequence(ys, batch_first=True, padding_value=-1.0)\n",
    "    lens  = torch.tensor(lens, dtype=torch.long)\n",
    "    return X_pad, y_pad, lens\n",
    "\n",
    "# Create DataLoaders for training and testing LoS regression models\n",
    "train_los_loader = DataLoader(\n",
    "    LoSDataset(Xtr_los, ytr_los, Ltr_los),\n",
    "    batch_size=64, shuffle=True, collate_fn=los_collate_fn\n",
    ")\n",
    "\n",
    "test_los_loader = DataLoader(\n",
    "    LoSDataset(Xte_los, yte_los, Lte_los),\n",
    "    batch_size=64, shuffle=False, collate_fn=los_collate_fn\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "WDVZ_ubCDLwv"
   },
   "outputs": [],
   "source": [
    "# Cell 25 — LSTM regression model\n",
    "# Define an LSTM based many to many regression model for predicting LoS at each timestep\n",
    "class LSTM_LoS(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim=64):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, 1)\n",
    "\n",
    "# Forward pass using packed sequences to handle variable-length inputs\n",
    "    def forward(self, x, lengths):\n",
    "        packed = pack_padded_sequence(x, lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
    "        packed_out, _ = self.lstm(packed)\n",
    "        out, _ = pad_packed_sequence(packed_out, batch_first=True)\n",
    "        preds = self.fc(out).squeeze(-1)\n",
    "        return preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "5ITEeAehDfQF"
   },
   "outputs": [],
   "source": [
    "# Cell 26 — Loss & metrics (MSE / RMSE / MAE / R²)\n",
    "# Initialize LoS regression model, loss function and evaluation metrics with masking\n",
    "los_model = LSTM_LoS(input_dim=len(los_feature_cols)).to(device)\n",
    "los_optimizer = torch.optim.Adam(los_model.parameters(), lr=1e-3)\n",
    "los_criterion = nn.MSELoss()\n",
    "\n",
    "# Define masked mean squared error to ignore padded timesteps\n",
    "def masked_mse(pred, true):\n",
    "    mask = (true != -1)\n",
    "    return los_criterion(pred[mask], true[mask])\n",
    "\n",
    "# Evaluate LoS model using MSE, RMSE, MAE, and R² on non-padded timesteps\n",
    "@torch.no_grad()\n",
    "def eval_los(loader):\n",
    "    los_model.eval()\n",
    "    all_preds, all_true = [], []\n",
    "\n",
    "    for X_pad, y_pad, lengths in loader:\n",
    "        X_pad = X_pad.to(device)\n",
    "        y_pad = y_pad.to(device)\n",
    "\n",
    "        preds = los_model(X_pad, lengths)\n",
    "        mask = (y_pad != -1)\n",
    "\n",
    "        all_preds.append(preds[mask].cpu().numpy())\n",
    "        all_true.append(y_pad[mask].cpu().numpy())\n",
    "\n",
    "# Aggregate predictions and compute regression metrics\n",
    "    y_pred = np.concatenate(all_preds)\n",
    "    y_true = np.concatenate(all_true)\n",
    "\n",
    "    mse  = np.mean((y_pred - y_true) ** 2)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae  = np.mean(np.abs(y_pred - y_true))\n",
    "    r2   = 1 - np.sum((y_true - y_pred) ** 2) / np.sum((y_true - np.mean(y_true)) ** 2)\n",
    "\n",
    "    return mse, rmse, mae, r2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dbNv3_EgDmNW",
    "outputId": "da435364-10a4-4976-8140-ca419a07a76a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 | TrainLoss=4724.842 | MSE=61.063 | RMSE=7.814 | MAE=3.896 | R2=-0.164\n",
      "Epoch 02 | TrainLoss=3876.712 | MSE=54.040 | RMSE=7.351 | MAE=3.671 | R2=-0.030\n",
      "Epoch 03 | TrainLoss=3743.927 | MSE=49.871 | RMSE=7.062 | MAE=3.621 | R2=0.050\n",
      "Epoch 04 | TrainLoss=3373.178 | MSE=46.798 | RMSE=6.841 | MAE=3.435 | R2=0.108\n",
      "Epoch 05 | TrainLoss=3227.264 | MSE=45.155 | RMSE=6.720 | MAE=3.307 | R2=0.140\n",
      "Epoch 06 | TrainLoss=3096.757 | MSE=44.132 | RMSE=6.643 | MAE=3.317 | R2=0.159\n",
      "Epoch 07 | TrainLoss=2989.528 | MSE=43.649 | RMSE=6.607 | MAE=3.253 | R2=0.168\n",
      "Epoch 08 | TrainLoss=2992.253 | MSE=43.503 | RMSE=6.596 | MAE=3.260 | R2=0.171\n",
      "Epoch 09 | TrainLoss=2883.582 | MSE=43.071 | RMSE=6.563 | MAE=3.242 | R2=0.179\n",
      "Epoch 10 | TrainLoss=2828.117 | MSE=42.822 | RMSE=6.544 | MAE=3.231 | R2=0.184\n",
      "Epoch 11 | TrainLoss=2835.104 | MSE=42.923 | RMSE=6.552 | MAE=3.253 | R2=0.182\n",
      "Epoch 12 | TrainLoss=2745.737 | MSE=42.879 | RMSE=6.548 | MAE=3.314 | R2=0.183\n",
      "Epoch 13 | TrainLoss=2749.469 | MSE=42.938 | RMSE=6.553 | MAE=3.298 | R2=0.182\n",
      "Epoch 14 | TrainLoss=2601.875 | MSE=43.056 | RMSE=6.562 | MAE=3.296 | R2=0.180\n",
      "Epoch 15 | TrainLoss=2637.596 | MSE=43.318 | RMSE=6.582 | MAE=3.360 | R2=0.175\n",
      "Early stopping.\n"
     ]
    }
   ],
   "source": [
    "# Cell 27 — Train LoS regression model\n",
    "# Train the LoS LSTM using masked MSE loss with early stopping based on test RMSE\n",
    "EPOCHS = 20\n",
    "best_rmse = np.inf\n",
    "patience = 5\n",
    "bad = 0\n",
    "\n",
    "# Training loop with validation based early stopping\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    los_model.train()\n",
    "    total_loss = 0.0\n",
    "\n",
    "    for X_pad, y_pad, lengths in train_los_loader:\n",
    "        X_pad = X_pad.to(device)\n",
    "        y_pad = y_pad.to(device)\n",
    "\n",
    "        los_optimizer.zero_grad()\n",
    "        preds = los_model(X_pad, lengths)\n",
    "        loss = masked_mse(preds, y_pad)\n",
    "        loss.backward()\n",
    "        los_optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "# Evaluate model performance on the test set after each epoch\n",
    "    mse, rmse, mae, r2 = eval_los(test_los_loader)\n",
    "\n",
    "    print(f\"Epoch {epoch:02d} | TrainLoss={total_loss:.3f} | MSE={mse:.3f} | RMSE={rmse:.3f} | MAE={mae:.3f} | R2={r2:.3f}\")\n",
    "\n",
    "    if rmse < best_rmse:\n",
    "        best_rmse = rmse\n",
    "        bad = 0\n",
    "        torch.save(los_model.state_dict(), \"best_lstm_los.pt\")\n",
    "    else:\n",
    "        bad += 1\n",
    "        if bad >= patience:\n",
    "            print(\"Early stopping.\")\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AEfyw82CDvgo",
    "outputId": "8626866e-b5da-444e-ba20-d0af2aae476a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_85/3093555071.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  los_model.load_state_dict(torch.load(\"best_lstm_los.pt\", map_location=device))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(42.822174, 6.543865, 3.230691, 0.1840606927871704)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 28 — Final LoS test performance\n",
    "# Load the best LoS model and report final regression metrics on the test set\n",
    "los_model.load_state_dict(torch.load(\"best_lstm_los.pt\", map_location=device))\n",
    "final_mse, final_rmse, final_mae, final_r2 = eval_los(test_los_loader)\n",
    "\n",
    "final_mse, final_rmse, final_mae, final_r2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 335
    },
    "id": "LBK9sYFeEMGh",
    "outputId": "34346072-ccb7-4599-aa57-3cdabb81dcb9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    9388.000000\n",
       "mean        4.919814\n",
       "std         7.635377\n",
       "min        -0.867361\n",
       "25%         1.135417\n",
       "50%         2.838194\n",
       "75%         5.724653\n",
       "max       207.152778\n",
       "Name: LoS, dtype: float64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 28.5 - Describe the distribution of Length of Stay values\n",
    "train[\"LoS\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "jp-nzxbzmxwP"
   },
   "outputs": [],
   "source": [
    "# Cell 29 — Feature importance for LoS (Permutation Importance)\n",
    "# Define permutation based feature importance for LoS regression using RMSE increase\n",
    "@torch.no_grad()\n",
    "def permutation_importance_lstm_regression(\n",
    "    model, loader, feature_cols, baseline_rmse\n",
    "):\n",
    "    model.eval()\n",
    "    importances = []\n",
    "\n",
    "# Define permutation-based feature importance for LoS regression using RMSE increase\n",
    "    for j, feat in enumerate(feature_cols):\n",
    "        all_preds, all_true = [], []\n",
    "\n",
    "        for X_pad, y_pad, lengths in loader:\n",
    "            X_pad = X_pad.clone()\n",
    "            y_pad = y_pad.to(device)\n",
    "\n",
    "            vals = X_pad[:, :, j].cpu().numpy().flatten()\n",
    "            np.random.shuffle(vals)\n",
    "            X_pad[:, :, j] = torch.tensor(\n",
    "                vals.reshape(X_pad[:, :, j].shape),\n",
    "                dtype=X_pad.dtype\n",
    "            )\n",
    "\n",
    "            X_pad = X_pad.to(device)\n",
    "            preds = model(X_pad, lengths)\n",
    "\n",
    "            mask = (y_pad != -1)\n",
    "            all_preds.append(preds[mask].cpu().numpy())\n",
    "            all_true.append(y_pad[mask].cpu().numpy())\n",
    "\n",
    "        y_pred = np.concatenate(all_preds)\n",
    "        y_true = np.concatenate(all_true)\n",
    "\n",
    "        rmse = np.sqrt(np.mean((y_pred - y_true) ** 2))\n",
    "        importances.append(rmse - baseline_rmse)\n",
    "\n",
    "# Return ranked feature importances as RMSE increase after shuffling each feature\n",
    "    return pd.DataFrame({\n",
    "        \"feature\": feature_cols,\n",
    "        \"importance_rmse_increase\": importances\n",
    "    }).sort_values(\"importance_rmse_increase\", ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 519
    },
    "id": "Mnx7bQdMm0w7",
    "outputId": "05215e91-412b-4449-896e-b88e818a873f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance_rmse_increase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>admission_type_EU OBSERVATION</td>\n",
       "      <td>0.143984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>admission_type_DIRECT OBSERVATION</td>\n",
       "      <td>0.054935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>admission_type_EW EMER.</td>\n",
       "      <td>0.048702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>admission_type_OBSERVATION ADMIT</td>\n",
       "      <td>0.044526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>admission_location_TRANSFER FROM HOSPITAL</td>\n",
       "      <td>0.042712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>admission_location_EMERGENCY ROOM</td>\n",
       "      <td>0.042135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>ccs_emb_15</td>\n",
       "      <td>0.038873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>admission_type_URGENT</td>\n",
       "      <td>0.029407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>admission_type_DIRECT EMER.</td>\n",
       "      <td>0.025131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>admission_type_ELECTIVE</td>\n",
       "      <td>0.024276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>admission_type_AMBULATORY OBSERVATION</td>\n",
       "      <td>0.021689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>ccs_emb_5</td>\n",
       "      <td>0.021620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>ccs_emb_6</td>\n",
       "      <td>0.021458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>ccs_emb_8</td>\n",
       "      <td>0.016764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>admission_location_PROCEDURE SITE</td>\n",
       "      <td>0.016566</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      feature  importance_rmse_increase\n",
       "8               admission_type_EU OBSERVATION                  0.143984\n",
       "6           admission_type_DIRECT OBSERVATION                  0.054935\n",
       "9                     admission_type_EW EMER.                  0.048702\n",
       "10           admission_type_OBSERVATION ADMIT                  0.044526\n",
       "17  admission_location_TRANSFER FROM HOSPITAL                  0.042712\n",
       "14          admission_location_EMERGENCY ROOM                  0.042135\n",
       "49                                 ccs_emb_15                  0.038873\n",
       "12                      admission_type_URGENT                  0.029407\n",
       "5                 admission_type_DIRECT EMER.                  0.025131\n",
       "7                     admission_type_ELECTIVE                  0.024276\n",
       "4       admission_type_AMBULATORY OBSERVATION                  0.021689\n",
       "39                                  ccs_emb_5                  0.021620\n",
       "40                                  ccs_emb_6                  0.021458\n",
       "42                                  ccs_emb_8                  0.016764\n",
       "16          admission_location_PROCEDURE SITE                  0.016566"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 30 - Feature importance for leangth of stay (Permutation Importance)\n",
    "# Compute baseline RMSE and estimate feature importance for LoS using permutation based RMSE increase\n",
    "_, baseline_rmse, _, _ = eval_los(test_los_loader)\n",
    "\n",
    "# Apply permutation importance to rank LoS features by increase in RMSE\n",
    "feature_importance_los = permutation_importance_lstm_regression(\n",
    "    model=los_model,\n",
    "    loader=test_los_loader,\n",
    "    feature_cols=los_feature_cols,\n",
    "    baseline_rmse=baseline_rmse\n",
    ")\n",
    "\n",
    "feature_importance_los.head(15)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
