{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf1228e-aea8-49fd-98c2-a7acd760de45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder, LabelEncoder\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, Masking, Embedding, Concatenate\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# ============================\n",
    "# 1️⃣ Load Data\n",
    "# ============================\n",
    "\n",
    "train_df = pd.read_csv(\"../data/train.csv\") # Training Set\n",
    "test_df = pd.read_csv(\"../data/test.csv\") # Testing Set\n",
    "\n",
    "# Sort by subject and admission\n",
    "train_df = train_df.sort_values(by=['subject_id', 'admission_id'])\n",
    "\n",
    "# ============================\n",
    "# 2️⃣ Scaling \n",
    "# ============================\n",
    "\n",
    "# Normalise Age\n",
    "scaler_age = MinMaxScaler()\n",
    "train_df['age_scaled'] = scaler_age.fit_transform(train_df[['age']])\n",
    "test_df['age_scaled'] = scaler_age.transform(test_df['age'])\n",
    "\n",
    "\n",
    "# Normalize Length of Stay\n",
    "scaler_los = MinMaxScaler()\n",
    "train_df['LoS_scaled'] = scaler_los.fit_transform(train_df[['LoS']])\n",
    "test_df['LoS_scaled'] = scaler_los.fit_transform(test_df[['LoS']])\n",
    "\n",
    "# Normalize Length of Stay\n",
    "scaler_erlos = MinMaxScaler()\n",
    "train_df['ER_LoS_scaled'] = scaler_erlos.fit_transform(train_df[['ER_LoS']])\n",
    "test_df['ER_LoS_scaled'] = scaler_erlos.fit_transform(test_df[['ER_LoS']])\n",
    "\n",
    "# ============================\n",
    "# 4️⃣ Build sequences per subject\n",
    "# ============================\n",
    "\n",
    "def build_sequences(df, feature_cols, target_col):\n",
    "    subjects = df['subject_id'].unique()\n",
    "    sequences = []\n",
    "    targets = []\n",
    "    \n",
    "    for subj in subjects:\n",
    "        subj_data = df[df['subject_id'] == subj].sort_values(by='admission_id')\n",
    "        seq_features = subj_data[feature_cols].values\n",
    "        seq_target = subj_data[target_col].values\n",
    "        \n",
    "        sequences.append(seq_features)\n",
    "        targets.append(seq_target)\n",
    "    \n",
    "    # Pad sequences to max length\n",
    "    max_seq_len = max(len(s) for s in sequences)\n",
    "    X_padded = pad_sequences(sequences, maxlen=max_seq_len, dtype='float32', padding='pre', truncating='pre')\n",
    "    y_padded = pad_sequences(targets, maxlen=max_seq_len, dtype='float32', padding='pre', truncating='pre')\n",
    "    \n",
    "    return X_padded, y_padded, max_seq_len\n",
    "\n",
    "# Suppose these are all columns in your dataframe\n",
    "all_columns = train_df.columns.tolist()\n",
    "exclude_features = ['subject_id', 'hadm_id', 'hospital_expire_flag', 'days_until_death']\n",
    "feature_cols = [c for c in all_columns if c not in exclude_features]\n",
    "\n",
    "target_col = 'hospital_expire_flag'\n",
    "\n",
    "X_train, y_train, max_seq_len = build_sequences(train_df, feature_cols, target_col)\n",
    "X_test, y_test, _ = build_sequences(test_df, feature_cols, target_col)\n",
    "\n",
    "# ============================\n",
    "# 5️⃣ Build LSTM model\n",
    "# ============================\n",
    "\n",
    "num_features = X_train.shape[2]\n",
    "\n",
    "inputs = Input(shape=(max_seq_len, num_features))\n",
    "x = Masking(mask_value=0.0)(inputs)  # Ignore padded timesteps\n",
    "x = LSTM(64)(x)  # Return output of last timestep\n",
    "outputs = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model = Model(inputs, outputs)\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# ============================\n",
    "# 6️⃣ Train model\n",
    "# ============================\n",
    "\n",
    "# Optionally handle class imbalance\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "class_weights = class_weight.compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(y_train[:, -1]),\n",
    "    y=y_train[:, -1]\n",
    ")\n",
    "class_weights_dict = {i: w for i, w in enumerate(class_weights)}\n",
    "\n",
    "model.fit(\n",
    "    X_train, y_train[:, -1],\n",
    "    validation_data=(X_test, y_test[:, -1]),\n",
    "    epochs=10,\n",
    "    batch_size=32,\n",
    "    class_weight=class_weights_dict\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
